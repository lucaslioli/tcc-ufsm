%%%% Arquivo base para o documento - ver. 1.00 (24/02/2016)
% % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % 
%%%%%% MDT UFSM 2015 %%%%%%%%%%
% % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % 
% % %  OPÇÕES DE COMPILAÇÃO  %%%%%%%%%%%


% % % % % PAGINAÇÃO
% % % PAGINAÇÃO SIMPLES (FRENTE): PARA TRABALHOS COM MENOS DE 100 PAGINAS
\documentclass[oneside,openright,12pt]{ufsm_2015} %%%%% OPÇÃO PADRÃO -> PAGINAÇÃO SIMPLES. PARA TRABALHOS COM MAIS DE 100 PAGINAS COMENTE ESTA LINHA E DESCOMENTE A LINHA 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% PAGINAÇÃO DUPLA (FRENTE E VERSO): PARA TRABALHOS COM MAIS DE 100 PAGINAS
% \documentclass[twoside,openright,12pt]{ufsm_2015}  %%%% PARA MAIS DE 100 PAGINAS DESCOMENTAR
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
%%%%%%%%% DEFINIÇÃO PADRÃO DE PACOTES -- ALTERE POR SUA CONTA E RISCO
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epsf,amsfonts}
\usepackage{amsfonts}
\usepackage{epstopdf}
\usepackage{float}
% % % %  PACOTE DE CODIFICAÇÃO - PADRÃO = UTF8
\usepackage[utf8]{inputenc}  %utf8
% \usepackage[latin1]{inputenc}   % europeu
% % % % % % % % % % % 
\usepackage[brazil]{babel}
\usepackage[T1]{fontenc}
\usepackage{indentfirst}
\usepackage{textcomp}
\usepackage{setspace}
\usepackage{picinpar}
\usepackage{ifthen}
\usepackage{path}
\usepackage{scalefnt}
\usepackage{tocloft}
\usepackage[overload]{textcase}

\usepackage{listings}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % FIM DA DEFINIÇÃO PADRÃO DE PACOTES  % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

% % % % % % % % PACOTES PESSOAIS % % % % % % % %  

% Pacotes utilizados para gerar os gráficos.
\usepackage{comment}
\usepackage{subfigure}
\usepackage{xcolor,colortbl}
\usepackage{tikz,pgfplots}
\usepackage{forest}
%\usepgflibrary{patterns}
\usetikzlibrary{patterns}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

% Configuração da área máxima que pode ser utilizada por imagem de gráfico.
\pgfplotsset{width=8cm,height=8cm,compat=1.8}

% Configuração para a exibição das árvores de decisão
\tikzset{
  treenode/.style = {shape=rectangle, rounded corners,
                     draw, align=center,
                     top color=white, bottom color=blue!20},
  root/.style     = {treenode, font=\Large, bottom color=red!30},
  env/.style      = {treenode, top color=white, bottom color=gray!20},
  dummy/.style    = {circle, draw, top color=white, bottom color=gray!10}
}

% Configuração de cores RGB
\definecolor{myred}{RGB}{215,21,21}
\definecolor{myblue}{RGB}{0,130,230}

% Configuração para a exibição do caption
\makeatletter
\renewcommand{\ALG@name}{Algoritmo}
\renewcommand{\listalgorithmname}{Lista de \ALG@name s}

% % % % % %  DEFINIÇÕES PESSOAIS  


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % DADOS DO TRABALHO % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

% % % % % % % % % % INFORMAÇÕES INSTITUCIONAIS % % % % % % % % % % 
% % CENTRO DE ENSINO DA UFSM
\centroensino{Centro de Tecnologia}  %%% NOME POR EXTENSO
\centroensinosigla{CT}  %%% SIGLA

% % CURSO DA UFSM
\nivelensino{Bacharelado}  %%%%%%% NÍVEL DE ENSINO 
\curso{Sistemas de Informação}   %%%%% NOME POR EXTENSO
\ppg{PPGALGO}   %%%%%% SIGLAregister_error_handler
\statuscurso{Curso}  %%%% STATUS= {Programa} ou {Curso}


% % % % % % % % % % INFORMAÇÕES DO AUTOR % % % % % % % % % % 
\author{Lucas Lima de Oliveira}   %%%%% AUTOR DO TRABALHO
\sexo{M} %%%% SEXO DO AUTOR -> M=masculino   F=feminino (IMPORTANTE PARA AJUSTAR PAGINAS PRE-TEXTUAIS)
\grauensino{Graduação}    %%%%%%%% GRAU DE ENSINO A SER CONCLUÍDO
\grauobtido{Bacharel}    %%%%% TITULO OBTIDO
\email{loliveira@inf.ufsm.com.br}   %%%% E-MAIL PARA CATALOGRÁFICA (COPYRIGHT) - OBRIGATÓRIO
% \endereco{Nome da Rua, n. 999} %%%% ENDEREÇO PARA CATALOGRÁFICA (COPYRIGHT) - OPCIONAL
% \fone{11 2222 3333} %%%% TELEFONE PARA CATALOGRÁFICA (COPYRIGHT) FORMATO {11 2222 3333} - OPCIONAL
% \fax{11 2222 3333}  %%%% FAX PARA CATALOGRÁFICA (COPYRIGHT) FORMATO {11 2222 3333} - OPCIONAL


% % % % % % % % % % INFORMAÇÕES DA BANCA % % % % % % % % % % 
% OBSERVAÇÕES: O CAMPO ORIENTADOR É OBRIGATÓRIO E NÃO DEVE SER COMENTADO
% % % % % %    OS DEMAIS MEMBROS DA BANCA (COORIENTADOR E DEMAIS PROFESSORES) QUANDO COMENTADOS NÃO APARECEM NA FOLHA DE APROVAÇÃO (O LAYOUT DA FOLHA DE APROVAÇÃO ESTA PREPARADO PARA O ORIENTADOR E ATE MAIS 4 MEMBROS NA BANCA

\orientador{Sérgio Luís Sardi Mergen}{Dr}{UFSM}{M}{P}  %%%INFORMAÇÕES SOBRE ORIENTADOR: OS CAMPOS SÃO:{NOME}{SIGLA DA TITULAÇÃO}{SIGLA DA INSTITUIÇÃO DE ORIGEM}{SEXO} M=masculino F=feminino {PARTE DA BANCA?} P=presidente M=Membro  N=Não faz parte

% \coorientador{Coorientador}{Dr}{AAAA}{M}{M} %%%INFORMAÇÕES SOBRE CO-ORIENTADOR: OS CAMPOS SÃO:{NOME}{SIGLA DA TITULAÇÃO}{SIGLA DA INSTITUIÇÃO DE ORIGEM}{SEXO} M=masculino   F=feminino {PARTE DA BANCA?} P=presidente  M=Membro  N=Não faz parte

\bancaum{João Carlos Damasceno Lima}{Dr}{UFSM}{M}{M}  %%%INFORMAÇÕES SOBRE PRIMEIRO NOME DA BANCA: OS CAMPOS SÃO:{NOME}{SIGLA DA TITULAÇÃO}{SIGLA DA INSTITUIÇÃO DE ORIGEM}{SEXO} M=masculino   F=feminino {PARTE DA BANCA?} P=presidente  M=Membro  N=Não faz parte

\bancadois{Joaquim Assunção}{Dr}{UFSM}  %%%INFORMAÇÕES SOBRE SEGUNDO NOME DA BANCA: OS CAMPOS SÃO:{NOME}{SIGLA DA TITULAÇÃO}{SIGLA DA INSTITUIÇÃO DE ORIGEM}

% \bancatres{Banca Três}{Dra}{CCCC} %%%INFORMAÇÕES SOBRE TERCEIRO NOME DA BANCA: OS CAMPOS SÃO:{NOME}{SIGLA DA TITULAÇÃO}{SIGLA DA INSTITUIÇÃO DE ORIGEM}

% \bancaquatro{Banca Quatro}{Dr}{DDDD} %%%INFORMAÇÕES SOBRE QUARTO NOME DA BANCA: OS CAMPOS SÃO:{NOME}{SIGLA DA TITULAÇÃO}{SIGLA DA INSTITUIÇÃO DE ORIGEM}

% \bancacinco{Banca Cinco}{Dra}{EEEE} %%%INFORMAÇÕES SOBRE QUARTO NOME DA BANCA: OS CAMPOS SÃO:{NOME}{SIGLA DA TITULAÇÃO}{SIGLA DA INSTITUIÇÃO DE ORIGEM}



% % % % % % % % % % INFORMAÇÕES SOBRE O TRABALHO % % % % % % % % % %
% % % %  TITULO DO TRABALHO
\titulo{Predição da popularidade de tuítes utilizando algoritmos de aprendizado de máquina} %% NÃO EH NECESSÁRIO CAPITALIZAR

% % % %  TITULO DO TRABALHO EM INGLÊS
\englishtitle{Prediction of Tweets' Popularity using machine learning algorithms}  %% NÃO EH NECESSÁRIO CAPITALIZAR

% % % ÁREA DE CONCENTRAÇÃO DO TRABALHO (CNPQ)
\areaconcentracao{Área de concentração do CNPq}
% % % TIPO DE TRABALHO - MANTER APENAS UMA LINHA DESCOMENTADA
% \tccg  %% Tese de <nível de ensino>
% \qualificacao %% Exame de Qualificação de <nível de ensino>
% \dissertacao %% Dissertação de <nível de ensino>
% \monografia %% Monografia
% \monografiag  %% Monografia (não exibe área de concentração)
% \tf  %% Trabalho Final de <nível de ensino>
% \tfg  %% Trabalho Final de Graduação (não exibe área de concentração)
% \tcc  %% Trabalho de Conclusão de Curso
\tccg  %% Trabalho de Conclusão de Curso (não exibe área de concentração)
% \relatorio  %% Relatório de Estágio (não exibe área de concentração)
% \generico   %%% Alternativa para aqueles cursos que não recebem o titulo de bacharel ou licenciado. Ex: engenharia, arquitetura, etc... Os campos abaixo também devem ser preenchidos
%     \tipogenerico{Tipo de trabalho em português}
%     \tipogenericoen{Tipo de trabalho em inglês}
%     \concordagenerico{o}
%     \graugenerico{Engenheiro Eletricista}
% % % DATA DA DEFESA 
\data{06}{12}{2018} %% FORMATO {DD}{MM}{AAAA}



% % % % %  ALGUMAS ENTRADAS PRE-TEXTUAIS
% % % % CASO NÃO QUEIRA UTILIZA-LAS COMENTE A LINHA DE COMANDO

% % % EPIGRAFE
\epigrafe{Que todos os nossos esforços estejam sempre focados no desafio à impossibilidade. Todas as grandes conquistas humanas vieram daquilo que parecia impossível.}{Charles Chaplin} %ESTRUTURA DE CAMPOS -> {Texto}{Autor}

% % % DEDICATÓRIA
\dedicatoria{
    Dedico este trabalho à minha mãe, Siminea Lima, mulher guerreira e batalhadora que me ensinou a sempre correr atrás dos sonhos e superar os obstáculos. Cada ensinamento passado me permitiu trilhar esse caminho.
}

% % % %  AGRADECIMENTOS
\agradecimentos{
    Agradeço primeiramente a minha mãe, Siminea Lima e namorada, Amanda Rodrigues, por todo apoio e suporte prestado durante toda a jornada da graduação. Sem vocês ao meu lado, nada disso seria possível.
    
    Agradeço também meu orientador, professor Sérgio Mergen, que além de ter participado da realização deste trabalho, também me deu suporte durante a graduação na realização de outras pesquisas. Agradeço imensamente por ter me acolhido nessa jornada, por todos os conselhos, amizade e por ter acreditado na minha capacidade.
    
    Agradeço minha família e entes queridos, que sempre estiveram presentes e me apoiaram a cada passo dado. O apoio de cada uma dessas pessoas foi fundamental nesta caminhada. A família é para sempre e devemos prezar por ela.
    
    A todos os demais professores do Curso de Sistemas de Informação que sempre mostram dedicação e comprometimento em transmitir seus conhecimentos. Cada ensinamento será levado para toda a vida.
    
    À Universidade Federal de Santa Maria, ao Centro de Tecnologia e à Coordenação do Curso de Sistemas de Informação por fornecer toda a estrutura necessária e proporcionar uma educação de qualidade.
    
    Ao Programa de Educação Tutorial do curso de Sistemas de Informação e todos colegas que fizeram parte do grupo junto comigo. Todas as atividades realizadas pelo grupo me permitiram evoluir como profissional e como ser humano. Ter participado deste grupo foi uma honra e me proporcionou muitas oportunidades de aprendizado.
    
    Acrescento agradecimentos especiais também aos meus amigos, já chamados de irmãos, Mateus Berndt e Gregory Fontoura, por toda parceria de sempre, suporte prestado e conselhos dados. A amizade de vocês sempre significou muito e têm sido essencial em todo meu caminho.

    Agradeço também todos os colegas e amigos feitos durante essa trajetória que permitiram trocas de conhecimentos e experiências inesquecíveis. Espero poder levar essas amizades por toda a vida.
    
    Também estendo agradecimentos especiais aos grandes amigos que hoje fazem parte da Confraria Socão na Cara. Essas amizades, criadas durante a graduação, foram fundamentais, proporcionando momentos de descontração e alívio da tensão quando houve sobrecarga de trabalhos.
}

% % % % %  RESUMO E PALAVRAS CHAVE DO RESUMO - OBRIGATÓRIO PARA MDT-UFSM
\resumo{
    É conhecida a popularidade do Twitter e o poder que um único tuíte pode ter nos dias de hoje, servindo, inclusive, como fonte para portais de notícias renomados. Muitas vezes, por parte de empresas e personalidades públicas que utilizam suas imagens para fins monetários, há uma grande preocupação com sua popularidade e o alcance das mensagens. Além de sua relevância, a simplicidade e o volume de dados trafegados pela plataforma diariamente, fazem dela uma fonte de dados muito poderosa. Focando na análise das mensagens veiculadas e no interesse dos usuários em aumentar seu número de seguidores, o objetivo deste trabalho é a elaboração de modelos, utilizando algoritmos de aprendizado de máquina, para realizar a predição e classificação da popularidade de tuítes com base em atributos extraídos do corpo das mensagens e o próprio texto. Agrega-se também à proposta deste trabalho a realização de análise variando a taxa de engajamento e considerando dados de contas individualizadas. Para alcançar os objetivos destacados, a metodologia adotada envolve a definição dos atributos de interesse, extração e processamento dos dados, além do estudo e aplicação de algoritmos de aprendizado de máquina para realizar a classificação dos tuítes.
}
\palavrachave{Aprendizado de Máquina Supervisionado. Classificação de Dados. Coleta de Dados.}
% "... deverão constar, no mínimo, três palavras-chave, iniciadas em
% letras maiúsculas, cada termo separado dos demais por ponto, e
% finalizadas também por ponto." MDT 2012

% % % % %  ABSTRACT E PALAVRAS CHAVE DO RESUMO - OBRIGATÓRIO PARA MDT-UFSM
\abstract{
    The popularity of Twitter and the power that a single tweet can have today are well-known, even serving as a source for renowned news portals. Many times, in cases of companies and public personalities who use their images for business purposes, there are a huge concern about popularity and the reach of messages. In addition to its relevance, the simplicity and volume of data sent by the platform make it a powerful data source. Focusing on the analysis of the messages and in the desire of the users to increase the number of followers, the purpose of this work is the elaboration of models, using algorithms of machine learning, to make predictions and classifications of the tweets' popularity based attributes extracted from the body and the text itself. We also perform, analysis modifying the engagement rate and considering data from specific users' account. In order to reach these goals, the methodology adopted involves the definition of attributes, extraction and processing of data, as well as the study and application of machine learning algorithms to perform the classification of tweets.
}
\keywords{Supervised Machine Learning. Data Classification. Data collection.}


% % %  ATIVAÇÃO DE LISTAS E PAGINAS ESPECIAIS
% % %  PARA QUE NÃO APAREÇAM NO TEXTO DESCOMENTE A LINHA ABAIXO -> POR PADRÃO TODAS ESTÃO ATIVIDADES

% % LISTA DE FIGURAS 
% \semfiguras   %%(QUANDO ATIVADA NÃO EXIBE A LISTA)
% % LISTA DE GRÁFICOS 
\semgraficos   %%(QUANDO ATIVADA NÃO EXIBE A LISTA)
% % LISTA DE ILUSTRAÇÕES 
\semilustracoes  %%(QUANDO ATIVADA NÃO EXIBE A LISTA)
% % LISTA DE TABELAS 
% \semtabelas   %%(QUANDO ATIVADA NÃO EXIBE A LISTA)
% % LISTA DE QUADROS 
\semquadros   %%(QUANDO ATIVADA NÃO EXIBE A LISTA)
% % LISTA DE APÊNDICES 
% \semapendices  %%(QUANDO ATIVADA NÃO EXIBE A LISTA)
% % LISTA DE ANEXOS 
% \semanexos   %%(QUANDO ATIVADA NÃO EXIBE A LISTA)



% % % %  LISTA DE ABREVIATURAS E SIGLAS
%%%%%%%% OBS: O espaço entre colchetes \item[] e um ambiente matemático
%%%%%%%% para não utilizar comente as linhas abaixo.
\siglamax{WEKA} %%%% coloque aqui a maior sigla (indentação)
\listadeabreviaturasesiglas{
\item[API]  \textit{Application Programming Interface}
\item[ARFF] \textit{Attribute-Relation File Format}
\item[CART] \textit{Classification and Regression Trees}
\item[IA]   Inteligência Artificial
\item[LMT]  \textit{Logistic Model Trees}
\item[LSTM] \textit{Long Short-Term Memory}
\item[PCA]  \textit{Principal Component Analysis}
\item[RNN]  \textit{Recurrent Neural Network}
\item[SVM]  \textit{Support Vector Machine}
\item[WEKA] \textit{Waikato Environment for Knowledge Analysis}
}

% % % %  LISTA DE SÍMBOLOS
%%%%%%%% OBS: O espaço entre colchetes \item[] e um ambiente matemático
%%%%%%%% para não utilizar comente as linhas abaixo.
% \simbolomax{(Re)2} %%%% coloque aqui o maior simbolo (indentação)
% \listadesimbolos{
% \item[u_*]	Escala de velocidade de fricção	
% \item[w_*]	Escala de velocidade convectiva
% \item[(Re)^2]	Maior simbolo da lista
% }


% % FICHA CATALOGRÁFICA
\semcatalografica  %%%%  (QUANDO ATIVADA NÃO EXIBE A FICHA CATALOGRÁFICA NECESSITA DO ARQUIVO DA FICHA: ficha_catalografica.pdf

% % % A FICHA CATALOGRÁFICA FORNECIDA PELA UFSM EH UM PDF DO TAMANHO A4
% % % OS COMANDOS ABAIXO DEFINEM AS MARGENS PARA CORTAR A FICHA FORNECIDA E COLOCA-LA COMO UMA FIGURA NO DOCUMENTO LATEX
\margemesquerda{4}   %%%% CORTE DE MARGEM ESQUERDA EM CM
\margemdireita{1.5}   %%%% CORTE DE MARGEM DIREITA EM CM
\margemsuperior{17}  %%%% CORTE DE MARGEM SUPERIOR EM CM
\margeminferior{3} %%%% CORTE DE MARGEM INFERIOR EM CM
% % %  DICA: IMPRIMA UMA COPIA DA FICHA CATALOGRÁFICA E FACA A MEDIDA DAS MARGENS!


% % FOLHA DE ERRADA (versão rudimentar...pode ser aprimorado)
% % para não utilizar comente as linhas abaixo.
% % deve ser preenchida como um ambiente tabular de quatro colunas:
% % pagina & linha & onde se lê & leia-a se \\
%\errata{
%10   &    10    & errado   & certo \\
%\hline
%12    &    5     & errado com um texto mais longo & certo agora com um texto mais longo\\
%\hline
%13   &    3    & $x^2$   & $2x$\\
%}
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % %  OPÇÕES DE FORMATAÇÃO % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % CAPITULO: por padrão alinhado a esquerda. Para ativar alinhamento centralizado descomente o comando abaixo

%\centralizado  %%%% <<< centraliza todos os capítulos

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % FONTES: descomente uma das opções. caso nenhuma seja ativada a classe usara a fonte padrão do latex

%% helvetica
% \usepackage[scaled]{helvet}
% \renewcommand*\familydefault{\sfdefault}

%% arial
\renewcommand{\rmdefault}{phv} % Arial
\renewcommand{\sfdefault}{phv} % Arial

%%times
% \usepackage{mathptmx}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % %  INICIO DO DOCUMENTO  % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %


\begin{document}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\pretextual  %%%% GERA AS PAGINAS PRE-TEXTUAIS   
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % CORPO DO TRABALHO - INCLUA OS SEUS TEXTOS AQUI
% % % % % SUGESTÃO -> UTILIZE ARQUIVOS EXTERNOS A PARTIR DO COMANDO \input


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % INICIO DAS PAGINAS TEXTUAIS % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % INTRODUÇÃO % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\introducao{

    \par Com a grande popularização dos chamados influenciadores digitais, é notável o crescimento das mídias sociais como meios de comunicação e divulgação de conteúdos. Neste cenário, onde o número de seguidores determina a sua influência, torna-se muito importante que essas personalidades compreendam seu público, pois conteúdos direcionados refletem diretamente no alcance de suas publicações. Dentre as redes sociais mais utilizadas atualmente, o Twitter é um meio de veiculação de mensagens que se destaca por sua simplicidade e objetividade. Embora não tenha o mesmo destaque que outras plataformas, como o Facebook ou o Instagram, o Twitter conta com cerca de 335 milhões de usuários ativos, segundo Statista~\footnote{\textit{Statista: }\texttt{https://www.statista.com/topics/737/twitter/}}, e em média 500 milhões de tuítes que são publicados diariamente, segundo \textit{Internet Live Stats}~\footnote{\textit{Internet Live Stats: }\texttt{http://www.internetlivestats.com/twitter-statistics/}}, o que faz dessa rede uma fonte de dados muito poderosa.

    \par Uma das preocupações de usuários do Twitter é alavancar sua popularidade, através do aumento no número de seguidores. Essa preocupação é fundamental para empresas e personalidades públicas que utilizam suas imagens para fins monetários. Nesses casos, o uso das redes sociais deve ser planejado e monitorado. Quando isso é realizado da maneira correta, a marca e/ou a pessoa ficam muito mais próximos de seus fãs e seguidores, o que consequentemente, faz sua popularidade e influência aumentarem. Um dos indicadores capazes de medir a influência de um usuário em redes sociais é a taxa de engajamento, que leva em consideração as interação dos usuários com as publicações de uma página. Dentre essas interações, podem ser considerados os retuítes, curtidas e comentários. Considerando esse fator, pode-se afirmar empiricamente que o aumento na quantidade de retuítes leva a um aumento na quantidade de seguidores, devido a propagação exponencial daquele conteúdo.

    \par Tendo em vista o interesse dos usuários em aumentar o alcance de suas postagens, poder identificar os fatores que têm maior influência sobre a popularidade de suas mensagens pode ser uma grande vantagem ao tentar aumentar o engajamento por parte de seus seguidores. Ser capaz de prever/estimar a popularidade que um tuíte poderá obter, baseando-se nas características presentes no corpo de sua mensagem, permite a realização de diferentes análises a cerca do conteúdo disseminado por aquela conta, o que pode trazer muitos benefícios aos usuários com relativa influência nessa rede social.

    \par Como afirma \cite{ieee:suh:10}, a propagação de um tuíte está diretamente ligada ao conteúdo e valor informativo contido nele. Nesse sentido, os autores avaliaram um conjunto de características extraídas das mensagens. Os resultados mostraram que a utilização de \textit{hashtags} e URLs são fatores muito significativos e que ajudam a impulsionar uma publicação. Apesar de ser um resultado muito relevante, o trabalho não realizou uma análise exaustiva das características que podem ser extraídas do corpo das mensagens de cada tuíte.
    
    \par É conhecido que hoje existem inúmeras pesquisas sendo realizadas envolvendo dados coletados do Twitter. Além de \cite{ieee:suh:10}, outros trabalhos relacionados que podem ser citados aqui, como \cite{acm:duan:2010}, \cite{benevenuto:2010}, \cite{acm:naveed:2011}, \cite{kharde:2016} e \cite{ieee:xu:2012}, tem como parte de seus objetivos, a análise e identificação de fatores impactantes no conteúdo das mensagens propagadas no Twitter. Outro fator em comum é que esses trabalhos também utilizam técnicas de aprendizado de máquina na realização de suas pesquisas.
    % \cite{acm:hong:2011}
    
    \par Dentre as principais técnicas utilizadas nestes trabalhos estão: Máquina de Vetores de Suporte (SVM, do inglês: \textit{Support Vector Machine}); árvores de decisão; Naive Bayes; e Regressão logística. No caso dos atributos utilizados nestas pesquisas, foram considerados como fatores de relevância: utilização de URLs e \textit{hashtags}; o alcance do autor do tuíte (podendo ser medido por seus seguidores ou métricas mais complexas); sentimento da mensagem; além dos fatores de popularidade relacionados a cada tuíte, como as curtidas e os retuítes.
    
    \par Ainda que cada um destes trabalhos apresentem contribuições muito significativas no contexto da descoberta de conhecimento através de dados coletados do Twitter com aprendizagem de máquina, as análises e experimentos são realizados de maneira genérica, sendo aplicadas as mesmas regras para todos os tipos de usuários. Além disso, as análises sobre os modelos não medem a qualidade das previsões com base em fatores variáveis de engajamento.

    \par Dentro deste contexto, o objetivo deste trabalho é elaborar modelos, utilizando algoritmos de aprendizado de máquina, para realizar a predição e classificação da popularidade de tuítes. Como entrada para os modelos, são utilizadas características extraídas de seu conteúdo e são consideradas taxas de engajamento variáveis. Para formar a base de dados, também é estabelecido como parte do objetivo monitorar e extrair tuítes de determinadas contas do Twitter que possuam certo grau de influência.
    
    \par No que se refere à aprendizagem de máquina, são testados os algoritmos já consolidados Naive Bayes e árvores de decisão. Escolha que foi tomada com base na popularidade e destaque dos algoritmos na solução de problemas de classificação de dados. Como entrada para estes modelos, são utilizados dados provenientes do pré-processamento dos tuítes coletados, sendo consideradas as seguintes características: tamanho em caracteres; sentimento (que mede a emoção transmitida); banalidade (que mede a relevância da mensagem); presença de \textit{hashtags} e URLs, que também foram utilizados nos trabalhos relacionados, além do próprio texto do tuíte.

    \par Este trabalho está estruturado nas seguintes seções. O capítulo \ref{sec:fund-teorica} apresenta a fundamentação teórica, abordando conceitos e algoritmos de aprendizado de máquina. O capítulo \ref{sec:proposta} apresenta a definição dos atributo e a arquitetura de extração de tuítes usada, que realiza desde a coleta até a preparação dos dados para análise. O capítulo \ref{sec:experimentos} apresenta as análises realizadas a partir dos dados coletados juntamente com a aplicação dos algoritmos de aprendizado de máquina estudados. O capítulo \ref{sec:conclusao} apresenta as considerações finais acerca do trabalho realizado.

% O capítulo \ref{sec:trab-relacionados} apresenta os trabalhos relacionados

}
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\geraintro  %%%% GERA INTRODUÇÃO   % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % FUNDAMENTAÇÃO TEÓRICA  % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\chapter{Fundamentação Teórica}
\label{sec:fund-teorica}

    \par Neste capítulo são apresentados os conceitos relacionados ao aprendizado de máquina, na seção \ref{sec:fund-aprend-maquina}, definindo as diferenças entre a aprendizagem supervisionada e a não supervisionada. Em seguida, na seção \ref{sec:fund-eng-features}, são abordados conceitos e técnicas para realização de engenharia de atributos. Já na seção \ref{sec:fund-alg-am-sup}, são apresentados alguns dos principais algoritmos do segmento supervisionado, os quais também foram utilizados na realização de experimentos no decorrer deste trabalho.

% % % % % % % % APRENDIZADO DE MÁQUINA % % % % % % % %

\section{Aprendizado de Máquina}
\label{sec:fund-aprend-maquina}

    \par Entende-se como sistemas inteligentes aqueles que são capazes de processar dados de entrada e ajustar padrões internos a fim de otimizar seus resultados de saída, de acordo com os objetivos esperados para aquele algoritmo. Dentro deste contexto, o aprendizado de máquina foca no treinamento desses algoritmos para melhorar seu desempenho. Esse processo está ligado com a redução de dimensionalidade, classificação e associação dos dados e previsão de comportamentos.

    \par Algoritmos de aprendizado de máquina (ou \textit{machine learning} em inglês) dividem-se em dois segmentos, aqueles que necessitam de uma supervisão para melhorar seus resultados e aqueles fazem esse processo de maneira independente. Nesta seção são apresentados esses dois tipos de algoritmos, especificando suas características e diferenças.

% % % % % % % % APRENDIZADO DE MÁQUINA SUPERVISIONADO % % % % % % % %

\subsection{Aprendizado de Máquina Supervisionado}
\label{sec:fund-am-sup}

    \par A aprendizagem supervisionada realiza o treinamento dos algoritmos com dados para os quais suas respostas já sejam conhecidas. Ou seja, dependem sempre da entrada de um padrão de valores e da comparação das respostas do sistema com aquelas consideradas corretas. Conforme o algoritmo é treinado, seus padrões vão sendo ajustados a fim de diminuir o erro e otimizar as respostas. 

    \par Os problemas solucionados através da aprendizagem supervisionada são divididos em problemas de regressão e classificação de dados, como ilustra a Figura \ref{fig:aprend-sup}. Segundo \cite{book:russell:10}, quando o resultado esperado pelo algoritmo for um conjunto finito de valores, (como fraco, mediano ou forte), trata-se de problema de classificação, pois os dados de entrada devem ser categorizados dentro daquele grupo. No caso do resultado esperado ser numérico, trata-se de um problema de regressão, na qual tenta-se identificar uma tendência nos valores com base nos dados de entrada.

    \par Nesse tipo de aprendizagem, o algoritmo recebe as entradas já categorizadas para realizar o treinamento e, a cada iteração, ajusta seus parâmetros para de obter a melhor saída, podendo ser, por exemplo, minimizar o erro, maximizar a precisão ou a acurácia. Frequentemente, após a etapa de treinamento, é realizada uma etapa de validação, passando ao algoritmo entradas sem classificação. É nesta etapa que seu desempenho pode ser realmente avaliado e, se necessário, o treinamento pode ser realizado novamente com novos ajustes em seus parâmetros.

    \pgfplotsset{compat=1.11}
    \begin{figure}[!ht]
    \caption{Exemplo de Problemas de Classificação e Regressão.}
    \centering
    \begin{tikzpicture}[scale=0.8]
    	\begin{axis}[%
        	title={(a) Problema de Classificação},
        	scatter/classes={%
            	a={draw=myblue, fill=myblue, mark size=5}, 
            	b={mark=x, draw=myred, fill=myred, mark size=7, line width=3pt}
            }
        ]
        \addplot[scatter,only marks,%
            scatter src=explicit symbolic]%
            table[meta=label] {
            	x y label
            	1   2.5 a
                1.2 2   a
                1.5 4   a
                1.7 4.5 a
                2   3   a
                2.2 3.5 a
                2.5 1.6 a
                2.5 5.5 a
                2.7 4   a
                3   2.4 a
                3.1 3   a
                3.2 5   a
                3.9 2.1 a
                4   3.5 a
                5   2.4 a
                4.5 6.2 b
                5   5.1 b
                5.5 7.1 b
                6   4.3 b
                6.3 5.5 b
                6   6.2 b
                6.5 4.6 b
                7   3.5 b
                7   5.7 b
                7.1 7.2 b
                7.2 6.5 b
                7.5 5   b
                8.1 3.2 b
                8.2 4   b
                8.4 6   b
                8.6 5.5 b
        	};
        \draw [ultra thick, dotted, draw=brown] (9,0) -- (0,9);
    	\end{axis}
    \end{tikzpicture}
    \hspace{0.25cm}
    \begin{tikzpicture}[scale=0.8]
    	\begin{axis}[%
        	title={(b) Problema de Regressão},
        	scatter/classes={%
            	a={draw=myblue, fill=myblue, mark size=5}, 
            	b={mark=x, draw=myred, fill=myred, mark size=7, line width=4pt}
            }
        ]
        \addplot[scatter,only marks,%
            scatter src=explicit symbolic]%
            table[meta=label] {
            	x y label
                1   2.5 a
                1.5 3.5 a
                2   3   a
                2.5 3.5 a
                2.7 4.5 a
                3   3   a
                3.5 4   a
                4   4.5 a
                4.5 3.7 a
                4.7 5.5 a
                5   4.5 a
                5.5 5   a
                6   6   a
                6.5 5.5 a
                7   6   a
                7.5 7.5 a
                8   7   a
                8.5 6.5 a
                9   8   a
        	};
        	\draw [ultra thick, dotted, draw=brown] (0,2) -- (10,8);
    	\end{axis}
    \end{tikzpicture}
    \fonte{Produção do próprio autor.} % \citeonline{site:medium:pedro}
    \label{fig:aprend-sup}
    \end{figure}

% % % % % % % % APRENDIZADO DE MÁQUINA NÃO SUPERVISIONADO % % % % % % % %

\subsection{Aprendizado de Máquina Não Supervisionado}
\label{sec:fund-am-nao-sup}

    \par No caso dos algoritmos de aprendizagem não supervisionada, os dados são recebidos sem nenhuma classificação prévia, impossibilitando o aferimento das respectivas classes para cada entrada. Consequentemente, conforme os dados vão sendo recebidos, o próprio algoritmo é responsável por identificar as relações e padrões presentes nos dados, o que por si só pode ser considerado um objetivo consideravelmente complexo a ser alcançado. A aprendizagem não supervisionada não prevê soluções específicas para realizar o treinamento e validação dos resultados, ou seja, não há um \textit{feedback} explícito sobre os resultados previstos.

    \par Como explica \cite{book:russell:10}, o exemplo mais comum de aprendizagem não supervisionada é o de agrupamento, onde o objetivo é detectar grupos potencialmente úteis dentro dos valores de entrada, que podem ser semelhantes ou estar relacionados por diferentes variáveis. A Figura \ref{fig:aprend-nao-sup} exemplifica as diferenças entre esses dois tipos de abordagem.

    \pgfplotsset{compat=1.11}
    \begin{figure}[!ht]
    \caption{Exemplo da diferença entre as diferentes abordagens.}
    \centering
    \begin{tikzpicture}[scale=0.8]
    	\begin{axis}[%
        	title={(a) Aprendizagem Supervisionada},
        	scatter/classes={%
            	a={draw=myblue, fill=myblue, mark size=5}, 
            	b={mark=x, draw=myred, fill=myred, mark size=7, line width=3pt}
            }
        ]
        \addplot[scatter,only marks,%
            scatter src=explicit symbolic]%
            table[meta=label] {
            	x y label
                1.7 2   a
                2.1 1.8 a
                2.1 2.3 a
                2.55 2.1 a
                2.1 2.05 a
                3.5 3.2 b
                3.8 3.5 b
                3.9 3.25 b
                4   3   b
                4.3 3.3 b
        	};
    	\end{axis}
    \end{tikzpicture}
    \hspace{0.25cm}
    \begin{tikzpicture}[scale=0.8]
    	\begin{axis}[%
        	title={(b) Aprendizagem Não supervisionada},
        	scatter/classes={%
            	a={draw=myblue, fill=myblue, mark size=5}, 
            	b={mark=x, draw=myred, fill=myred, mark size=7, line width=4pt}
            }
        ]
        \addplot[scatter,only marks,%
            scatter src=explicit symbolic]%
            table[meta=label] {
            	x y label
                1.7 2   a
                2.2 1.8 a
                2.1 2.3 a
                2.55 2.1 a
                2.1 2.05 a
                3.5 3.2 a
                3.8 3.5 a
                3.9 3.25 a
                4   3   a
                4.3 3.3 a
        	};
    	\end{axis}
    	\draw[myred, very thick] (1.4,1.4) circle (1.3);
    	\draw[myred, very thick] (5,5) circle (1.3);
    \end{tikzpicture}
    \fonte{Produção do próprio autor.} % \citeonline{site:medium:pedro}
    \label{fig:aprend-nao-sup}
    \end{figure}

% % % % % % % % ENGENHARIA DE ATRIBUTOS % % % % % % % %

\section{Engenharia de Atributos}
\label{sec:fund-eng-features}

    \par Engenharia de atributos (ou \textit{Feature Engineering}) é um conjunto de técnicas muito utilizadas no processo de aprendizado de máquina. Essas técnicas têm o objetivo de agregar valor mais significativo aos dados coletados e assim, melhorar os modelos de IA \cite{book:zheng:2018}.  Muitas vezes, o processo de engenharia de atributos por si só pode trazer melhores resultados independente dos algoritmos utilizados. Como já disse Peter Norvig, escritor de renomados livros na área de inteligência artificial e atualmente diretor de pesquisa no Google, "mais dados batem algoritmos inteligentes, mas dados melhores batem mais dados". Ou seja, mesmo utilizando algoritmos poderosos de aprendizagem de máquina, os resultados não serão tão bons se os dados não forem significativos.
    
    \par A escolha de quais técnicas utilizar está ligada, na maioria dos casos, tanto aos dados quanto ao modelo, pois alguns deles podem estar mais adaptados a um determinado tipo de atributo \cite{book:zheng:2018}. A Figura \ref{fig:feature-engineering} mostra onde a aplicação de engenharia de atributos se localiza no processo de aprendizagem de máquina e torna claro que as escolhas tomadas em qualquer uma das etapas têm influência direta nas etapas subsequentes.
    
    % IMAGEM
    \begin{figure}[ht]
        \caption{Engenharia de Atributos no processo de Aprendizado de Máquina}
        \centering
        \includegraphics[width=1\textwidth]{figuras/feature-engineering.png}
        \vspace{\baselineskip} %%% linha em branco para atender a norma
        \fonte{Traduzido de \cite{book:zheng:2018}}
        \label{fig:feature-engineering}
    \end{figure}
    
    \par Como mencionado, existem inúmeras técnicas de engenharia de atributos dependendo do tipo de dados, e para cada uma delas, existem diferentes estratégias de aplicação. No caso de dados textuais, existem técnicas para realizar a preparação do texto, ou pré-processamento, que podem envolver alguns procedimentos como transformação dos caracteres em letras minúsculas, lematização das palavras, remoção de acentuações, caracteres não textuais e palavras comuns (ou \textit{stopwords}). Já no caso de dados numéricos, podem ser aplicadas técnicas como:
    
    \begin{itemize}
        \item Preenchimento de valores faltantes, para evitar a perda de informações;
        \item Arredondamento de valores, para remover ruídos de muitas casas decimais;
        \item Normalização, para padronizar a escala dos valores;
        \item Transformação logarítmica, para reduzir a diferença na escala entre valores muito grandes e outros muito pequenos; Dentre outras.
    \end{itemize}
    
    \par Como consequência de todos os procedimentos, muitos atributos novos podem ser gerados e o processamento de todos eles pode se tornar muito custoso. Nestes casos, existem abordagens com o intuito de selecionar os atributos mais representativos dentre todos disponíveis. Dentre estas abordagens de seleção, pode-se citar Análise de Componentes Principais (PCA, do inglês: \textit{Principal Component Analysis}); método de filtragem, que busca identificar correlações entre os dados; método \textit{Wrapper}, que é baseado na tentativa e erro para encontrar a melhor combinação de atributos; e o método \textit{Embedded} (ou incorporado, em tradução livre), casos em que a seleção destes atributos já faz parte do modelo.
    
    \par Além destes já citados, outros métodos de engenharia de atributos que também podem ser aplicados sobre textos e valem a pena ser citados aqui é a vetorização do texto com técnicas como \textit{bag-of-words} \cite{mikolov:2013:2} e \textit{word-embeddings} \cite{mikolov:2013:1}, que buscam determinar a frequência e similaridade das palavras presentes nos textos.

% % % % % % % ALGORITMOS DE APRENDIZADO DE MÁQUINA SUPERVISIONADO % % % % % % %

\section{Algoritmos de aprendizado de máquina supervisionado}
\label{sec:fund-alg-am-sup}

    \par Dentro do escopo deste trabalho, que tem como um dos objetivos realizar a predição da popularidade de tuítes, utiliza-se aprendizagem de máquina supervisionada, pois os resultados esperados estão diretamente ligados à classificação dos dados. Neste tipo de modelo, para cada instância de treino, é conhecida sua classe, enquanto que na validação, o objetivo é descobrir a classe das instâncias. A justificativa na utilização deste tipo de algoritmo está ligada à tentativa de realizar a predição, uma vez que o alcance de tuítes futuros é desconhecido.
    
    \par Como mencionado, nesta seção são abordados alguns dos principais algoritmos que se encaixam no segmento de aprendizagem supervisionada e que são utilizados no decorrer deste trabalho, sendo eles: Naive Bayes e árvores de decisão. Para cada algoritmo apresentam-se suas características, funcionamento, vantagens e desvantagens em suas utilizações. Para exemplificação da aplicação de cada modelo, utiliza-se a frase em comum: ``\textit{With great power comes great responsibility}''.

% % % % % % % % NAIVE BAYES % % % % % % % %

\subsection{Naive Bayes}
\label{sec:fund-naive-bayes}

    \par A técnica Naive Bayes pode ser considerada como uma das mais populares para classificação de dados utilizando aprendizado de máquina. O algoritmo utiliza de métodos probabilísticos, baseados na Teoria Bayesiana, criada por Thomas Bayes no século XVIII. Para compreender melhor o funcionamento dessa técnica, é importante entender também um pouco sobre o teorema do qual ela teve origem.

    \par Como mostra \cite{book:russell:10}, o teorema, ou regra de Bayes é uma formula simples, definida pela Equação \ref{eq:teorema-bayes}, que vem da regra do produto de probabilidades, assumindo que \textit{prob(D|H) = prob(H|D)}, sendo H a hipótese a ser validada e D os dados observados, podendo ser tratados também como \textit{causa} e \textit{efeito}. Apesar de simples, essa regra é a base de grande parte dos sistemas de IA (Inteligência Artificial) que utilizam inferência probabilística.
    
    \begin{equation} \label{eq:teorema-bayes}
    prob(H|D) = \frac{prob(D|H)prob(H)}{prob(D)}
    \end{equation}
    
    \par Dividindo as partes do teorema, do lado esquerdo, \textit{prob(H|D)} é chamada de probabilidade posterior da hipótese após a realização do experimento; do lado direito, \textit{prob(D|H)} chamada função de verossimilhança, é a distribuição de probabilidade dos dados, a qual multiplica-se por \textit{prob(H)}, denominada \textit{Prior}, que é a probabilidade da hipótese ser verdadeira; por fim, o denominador \textit{prob(D)}, é a probabilidade total.
    
    \par Ainda que possa parecer um teorema simples, seu alcance está na sua capacidade de interpretação. No caso do modelo Naive Bayes, ou Bayes Ingênuo, assume-se que os atributos \textit{efeito} são condicionalmente independentes entre si, dada a \textit{causa} -- daí a denominação de ``ingênuo''. A distribuição probabilística deste modelo pode ser descrita conforme indica a Equação \ref{eq:naive-bayes}, sendo \textit{C} a classe, ou causa, que deve ser prevista, enquanto que o conjunto $\{x_1, ..., x_n\}$ são os atributos, ou efeitos.
    
    \begin{equation} \label{eq:naive-bayes}
    P(C | x_1, ..., x_n) = \alpha P(C)\prod_i{P(x_i | C)}
    \end{equation}
    
    \par Este modelo de aprendizagem é facilmente escalável para problemas maiores, funcionando muito bem com uma ampla variedade de aplicações, apesar de se destacar e ser comumente utilizado em uma série de algoritmos para classificação de textos. Além disso, este modelo não apresenta grandes complicações com dados ruidosos ou faltantes, podendo inclusive realizar previsões adequadas nestes casos. % Esses fatores fazem o Naive Bayes ser (provavelmente) o modelo de rede Bayesiana mais comumente utilizado em algoritmos de aprendizado de máquina.
    
    \par Tomando como exemplo a tradicional classificação de sentimentos em textos, como mencionado, o algoritmo irá assumir que as palavras de uma determinada mensagem não possuem uma relação entre si. Sendo assim, o classificador poderá presumir que uma frase seja positiva, caso a maioria das palavras presentes nela tenham maior probabilidade de ter este mesmo sentimento, independentemente do contexto em que foram utilizadas.
    
    \par Para classificar uma determinada frase, inicialmente é preciso montar uma base de treinamento, contendo a classificação dos dados de entrada, que no caso da análise de sentimentos, será positivo ou negativo. A partir destes dados, é criada uma tabela para guardar a frequência de cada uma das entradas com suas classes e a probabilidades de cada entrada. Para testar uma nova entrada, é calculada sua probabilidade para cada uma das possíveis classificações com base nas ocorrências anteriores. Para os casos em que o dado de teste não esteja presente na base de treinamento ou não foi classificado para uma das classes, técnicas adicionais devem ser usadas. Uma técnica muito comum aplicada para estes casos é a suavização de Laplace, que soma o valor 1 para todos os valores, desta forma, nenhuma operação é realizada utilizando o valor 0.
    
    \par Para exemplificar a classificação de um texto como popular ou não popular, será utilizada a frase apresentada no início da seção -- assumindo que ela possa ter sido extraída do Twitter -- e considerando a Tabela \ref{tab:naive-freq}  -- fictícia -- apresentada logo abaixo. Na tabela consta a frequência das palavras para cada classe e a probabilidade de cada uma. Para simplificar, o objetivo neste exemplo é classificar apenas a palavra ``\textit{great}'' como popular ou impopular. Neste caso, seriam realizadas as seguintes operações listadas na sequência, após a tabela.
    
    \begin{table}[ht]
        \caption{Exemplo de tabela com frequências de palavras e suas classes.}
        \centering
        \begin{tabular}{ c c c c }
            \hline
            Palavras & Popular & Impopular & Probabilidade \\
            \hline
            with & 1 & 2 & 3/21 = 0,14 \\
            great & 4 & 1 & 5/21 = 0,24 \\
            power & 2 & 3 & 5/21 = 0,24 \\
            comes & 3 & 2 & 5/21 = 0,24 \\
            responsibility & 1 & 2 & 3/21 = 0,14 \\
            \hline
            Total & 11 & 10 & \\
            \hline
            & & Popular & 11/21 = 0,52 \\
            & & Impopular & 10/21 = 0,48 \\
            \hline
        \end{tabular}
        \vspace{\baselineskip} %%% linha em branco para atender a norma
        \fonte{Produção do próprio Autor.}
        \label{tab:naive-freq}
    \end{table}
    
    \begin{align}
    P(great|popular) = 4/11 = 0.36 \\
    P(popular) = 8/14 = 0.52 \\
    P(great) = 4/14 = 0.24 \\
    P(great|unpopular) = 1/10 = 0.10 \\
    P(unpopular) = 6/14 = 0.48
    \end{align}
    
    \begin{align}
    P(popular|great) = 0.36 * 0.52 / 0.24 = 0.78 \\
    P(unpopular|great) = 0.10 * 0.48 / 0.24 = 0.20
    \end{align}
    
    \par A partir dos cálculos realizados, com arredondamentos, considerando os dados da Tabela \ref{tab:naive-freq} apresentada, obtém-se como resultado uma probabilidade maior para a palavra `\textit{great}' ser popular. Para realizar a classificação considerando toda a frase, essa operação é aplicada para cada palavra. As probabilidades resultantes para cada classe são multiplicadas e os resultados são aplicados na regra de Bayes, conforme a Equação \ref{eq:teorema-bayes}, para cada uma das possíveis classes. Como resultado, obteve-se uma probabilidade maior para a frase ser popular. Mesmo sendo um exemplo simples da aplicação da técnica Naive Bayes, é possível observar a facilidade da aplicação deste algoritmo para a classificação de dados utilizando um método probabilístico.

% % % % % % % % ÁRVORES DE DECISÃO % % % % % % % %

\subsection{Árvores de Decisão}
\label{sec:fund-arvores-decisao}

    \par Abstraindo o conceito computacional, uma árvore de decisão pode ser definida por um fluxograma, no qual cada nó, com exceção do último nível, representa um teste sobre as informações disponíveis. O ponto de partida é denominado nó raiz. A medida que os nós filhos vão sendo explorados, as informações são divididas com o objetivo de agrupá-las por similaridade e buscar o balanceamento entre os subgrupos. Ao percorrer toda a árvore, os últimos elementos, denominados nós folha, representam a decisão a ser tomada. Apesar de ser um conceito simples, a complexidade computacional desta técnica está no processo de indução da estrutura da árvore, feita de maneira automática e não-paramétrica, podendo lidar com dados multidimensionais. 
    
    \par Assim como outras técnicas dentro do escopo de aprendizagem supervisionada, árvores de decisão também são muito populares para a resolução de problemas de classificação de dados e regressão linear. Segundo \cite{book:han:11}, a popularização destes algoritmo na aprendizagem de máquina está diretamente ligada à sua característica não-paramétrica. Este fator permite a indução de árvores sem o total domínio ou configuração prévia dos dados, o que torna-se muito interessante no âmbito deste trabalho, no que se refere à descoberta de maneira exploratória.
    
    \par Ainda conforme \cite{book:han:11}, para realizar a classificação de dados, cada registro percorre um determinado caminho dentro da estrutura da árvore, partindo do nó raiz até o nó folha, que determina a classe para aquela entrada de dados. Para exemplificar, foi criada a árvore de decisão fictícia apresentada na Figura \ref{fig:exemplo_arvore}, que considera quatro atributos de uma mensagem de texto para considerá-la como popular ou não. Na figura, os nós com o formato retangular representam os testes feitos com cada registro de entrada, sendo indicado também o número de instâncias que estão naquele nó, partindo da raiz com 1000. Por sua vez, os nós com o formato circular são os nós folha, que representam a classificação final para indicar se a mensagem seria considerada como popular ou não.
    
    % GRÁFICO
    \begin{figure}[ht]
    \caption{Exemplo de árvore para classificação de um tuíte como popular.}
    \centering
    \begin{tikzpicture}
      [
        edge from parent/.style = {draw, -latex},
        every node/.style       = {font=\footnotesize},
        sibling distance        = 8em,
        level distance          = 5em,
        level 1/.style = {sibling distance=15em},
        level 2/.style = {sibling distance=8em},
        sloped,
      ]
      \node [env] {[1000] Sentimento positivo?}
        child { node [env] {[540] Maior que 140 caracteres?}
            child { node [dummy] {não} edge from parent node [above] {sim}}
            child { node [env] {[290] Possui \textit{hashtag}?}
                child { node [dummy] {não} edge from parent node [above] {sim}}
                child { node [dummy] {sim} edge from parent node [above] {não}}
                edge from parent node [above] {não}
            }
            edge from parent node [above] {sim}
        }
        child { node [env] {[460] Possui URL?}
            child { node [dummy] {sim} edge from parent node [above] {sim}}
            child { node [dummy] {não} edge from parent node [above] {não}}
            edge from parent node [above] {não}
        };
    \end{tikzpicture}
    \fonte{Produção do próprio Autor.}
    \label{fig:exemplo_arvore}
    \end{figure}
    
    \par Utilizando novamente a frase de exemplo apresentada no início da seção, ao aplicá-la na árvore de decisão apresentada, ela seria classificada como popular, pois percorreria o seguinte caminho: Sentimento positivo; Menor que 140 caracteres; e não possui \textit{hashtag}. Mesmo sendo um exemplo fictício e bastante simplificado, é possível perceber que pode haver uma correlação entre os atributos.
    
    \par Mesmo existindo vários algoritmos com diferentes propostas para realizar a indução de árvores de decisão, duas etapas estão presentes na grande maioria deles durante o construção da árvore. A seleção das medidas de atributos e a ``poda da árvore'' que, respectivamente, são responsáveis por definir quais a melhores partições dos dados; e por remover, ou reduzir, ruídos nas ramificações gerados durante o treinamento.
    
    \par Um dos algoritmos que merece destaque por ser referência neste âmbito, é o CART (\textit{Classification and Regression Trees}), criado em 1984 por um grupo de estatísticos (L. Breiman, J. Friedman, R. Olshen, and C. Stone). Ele realiza uma abordagem de construção recursiva de divisão e conquista partindo de cima para baixo, segundo \cite{book:han:11}.
    
    \par Com relação ao à técnica \textit{Naive Bayes}, apresentada na subseção anterior, a maior diferença e, talvez a mais significativa, dentre esses dois tipos de algoritmos, é que árvores de decisão são capazes de lidar com a correlação entre os diferentes atributos utilizados. Já o algoritmo ingênuo de bayes considera que os atributos são independentes entre si. Outra diferença que pode ser observada, é que o Naive Bayes também pode ser aplicado sobre o próprio texto, além dos atributos, enquanto que as árvores de decisão não.


% % % % % % % % REDES NEURAIS % % % % % % % %

\begin{comment}
\subsection{Redes Neurais e Aprendizagem Profunda} % Recorrentes
\label{sec:fund-redes-neurais}

    \par O conceito de redes neurais surgiu com o objetivo de simular o funcionamento dos neurônios do cérebro humano, capazes de realizar associações complexas em frações de segundos. Este tipo de rede funciona a partir da conexão entre nós na forma de um grafo dividido entre as camadas, que são divididas entre três tipos: camada de entrada; camada de saída; e camadas ocultas, que são todas as demais presentes entre a de entrada e de saída. 
    
    \par Apesar de ser um tópico muito popular atualmente, pesquisas envolvendo redes neurais artificiais não são tão recentes assim. Como apresentado em \cite{book:russell:10}, estudos na área de IA propondo modelos matemáticos de neurônios vem sendo realizados desde a década de 1940. De lá pra cá, segundo \citeonline{site:deep-learning}, os trabalhos neste âmbito evoluíram bastante e nos últimos anos se popularizou o uso de redes neurais de aprendizagem profunda (ou \textit{Deep Learning}), que vem sendo fundamental na implementação de sistemas inteligentes modernos, capazes de reconhecer rostos e vozes de diferentes pessoas.
    
    \par Conforme apresentado em \cite{book:russell:10}, a estrutura de uma rede neural é formada por nós matemáticos, representando neurônios, e ligações direcionadas, representando as conexões entre cada neurônio. Cada nó da rede aplica sobre sua entrada uma determinada função de ativação para gerar o valor de saída. As ligações tem o objetivo de propagar a ativação de um neurônio para o outro, sendo que cada ligação possui um determinado peso definindo força e sinal da conexão. 
    
    \par Existem diferentes funções de ativação e maneiras como a ligação entre os neurônios pode ser realizada, porém, existem duas formas para a realização destas conexões que configuram tipos de redes distintas: redes neurais com alimentação para frente (ou \textit{feed-forward}), em que suas conexões são realizadas em uma única direção, sem a presença de laços; e as Redes Neurais Recorrentes, comumente chamadas pela sigla RNN (do inglês \textit{Recurrent Neural Network}), as quais possuem laços que alimentam as entradas com suas próprias saídas, permitindo que esse tipo de rede possa armazenar memórias de curto prazo. Atualmente, a maioria dos modelos de redes profundas (\textit{deep-learning}) são totalmente baseados na estrutura de RNNs.
    
    \par Diferentemente dos primeiros modelos de redes neurais lançados, como Perceptron, os algoritmos de aprendizagem profunda modernos podem ser caracterizados por, além de recorrente, possuir várias camadas ocultas de neurônios, sendo que cada camada pode possuir diferentes tipos de função de ativação. A Figura \ref{fig:deep-learning} apresenta de forma visual a diferença na estrutura de camadas entre estes tipos de redes neurais.
    
    % IMAGEM
    \begin{figure}[ht]
        \caption{Rede Neural Simples e Rede Neural Profunda (\textit{Deep Learning})}
        \centering
        \includegraphics[width=1\textwidth]{figuras/deep-learning.png}
        \vspace{\baselineskip} %%% linha em branco para atender a norma
        \fonte{Traduzido de \citeonline{site:deep-learning}}
        \label{fig:deep-learning}
    \end{figure}
    
    \par Existem vários modelos de arquiteturas de redes neurais propostos, dentre eles, vale a pena citar: Redes Multicamadas Perceptrons; Redes de Hopfield; Redes Neurais Convolucionais; e Memória de Longo Prazo (LSTM, do inglês: \textit{Long Short-Term Memory}).
    
    % No contexto deste trabalho, durante a seção \ref{sec:experimentos}, correspondente aos experimentos, será dado destaque à arquitetura de redes convolucionais e LSTM, por se destacarem e ser muito utilizada no processamento de linguagem natural.
\end{comment}
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % TRABALHOS RELACIONADOS % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

%\chapter{Trabalhos Relacionados}
%\label{sec:trab-relacionados}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % PROPOSTA % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\chapter{Proposta}
\label{sec:proposta}

    \par A proposta deste trabalho é a elaboração de modelos, utilizando algoritmos de aprendizado de máquina supervisionado, para realizar a classificação da popularidade de tuítes em função da taxa de engajamento. Como entrada para tais modelos, são utilizadas características presentes no corpo das mensagens, incluindo o próprio texto. Para atingir esse objetivo, é necessário coletar os tuítes, extrair suas características e aplicar os algoritmos já mencionados para realizar o treinamento e classificação dos dados. A partir disso, esta seção apresenta a definição dos atributos, definição de popularidade, arquitetura de processamento dos tuítes e os classificadores utilizados na realização do trabalho.

% % % % % % % % DEFINIÇÃO DOS ATRIBUTOS % % % % % % % %

\section{Definição dos Atributos de Interesse}
\label{sec:prop-def-atributos}

    \par Como parte do objetivo deste trabalho é a correlação entre a popularidade e as características do texto de cada tuíte, é de fundamental importância a definição e extração de características relevantes que possam influenciar no interesse dos usuários sobre uma determinada mensagem. Esta etapa corresponde à definição dos atributos que serão extraídos de cada um dos tuítes coletados. Os itens abaixo definem cada um destes atributos e a razão de terem sido escolhidos:

    \par \textbf{Presença de URLs}: O uso de URLs em um tuíte pode indicar uma informação proveniente de outros meios, podendo ser sites de notícias ou outras mídias sociais, o que pode despertar, ou não, o interesse de usuários por um determinado tipo de informação. Esse atributo é representado pelo tipo de dados booleano, podendo ser verdadeiro ou falso.

    \par \textbf{Presença de \textit{hashtags}}: De maneira geral, as \textit{hashtags} são palavras-chave ou termos utilizados para indicar que uma determinada mensagem está diretamente ligada a um tópico ou discussão específica. De maneira semelhante ao uso de URLs, pode atrair o interesse de usuários por determinados tópicos. Este atributo também é do tipo booleano.

    \par \textbf{Tamanho da mensagem}: Essa característica é basicamente a contagem da quantidade de caracteres usados no corpo do tuíte, que pode fazer com que os usuários percam o interesse em ler seu conteúdo, por ser muito curto ou muito extenso. Por tratar-se de um valor contínuo, este atributo é representado por um valor inteiro.

    \par \textbf{Sentimento da mensagem:} O sentimento é um valor que classifica o teor do texto como positivo ou negativo. Esse fator pode estar diretamente ligado à intenção de cada usuário em propagar mensagens com um determinado humor. Este atributo também pode ser chamado de polaridade da mensagem e trata-se de um valor decimal, que pode variar entre -1 e 1, onde -1 corresponde a uma mensagem totalmente negativa, 0 corresponde a neutra e 1 corresponde a totalmente positiva.

    \par \textbf{Banalidade da mensagem:} No contexto deste trabalho, como também em \cite{artigo:oliveira:18}, a banalidade corresponde à importância do que foi escrito no corpo do tuíte, levando em consideração a presença de palavras que são frequentemente usadas em textos escritos. Sendo assim, quanto maior o número de palavras frequentes, mais banal é a mensagem. Este atributo é representado por um valor decimal, que varia entre 0 e 1, sendo que quanto mais próximo de 1, mais banal é a mensagem. O cálculo desta métrica utiliza a Equação \ref{eq:banalidade}, apresentada logo abaixo.

    \begin{equation} \label{eq:banalidade}
    \frac{\sum_{i=1}^n (freq(P_i))}{n}
    \end{equation}
    
    \par onde o conjunto $\{P_1, ..., P_n\}$ são as palavras da mensagem após a remoção de \textit{stopwords} (preposições e artigos que normalmente são descartados durante o processamento de um texto). Já a função $freq(P)$ retorna 1 caso a palavra $P$ seja frequente e zero caso não seja.

% % % % % % % % DEFINIÇÃO DE POPULARIDADE % % % % % % % %

\section{Definição de Popularidade}
\label{sec:prop-def-popularidade}

    \par De maneira geral, em mídias sociais, a popularidade de uma conta pode ser medida através da quantidade de seguidores que ela detém. Quanto maior o número de seguidores, mais influente, ou popular, a conta é considerada. Porém, este é um indicador simples que não determina o alcance real das publicações. Para isso, existem várias métricas que permitem uma medição mais precisa sobre o impacto causado pelas ações realizadas por um determinado usuário. Uma métrica muito conhecida e utilizada para medir o alcance real de um usuário sobre seus seguidores é a taxa de engajamento. Esse índice considera as interações dos fãs com os conteúdos publicados, de forma que quanto maior é essa interação, maior é o nível de engajamento.

    \par Como exposto em \cite{pillat:17}, para calcular a taxa de engajamento de uma determinada publicação, por convenção, é realizada a fórmula apresentada na Equação \ref{eq:engajamento}. Cada elemento da equação refere-se estritamente ao valor, em quantidade, obtido por cada publicação. Trazendo para a realidade do Twitter, os compartilhamentos são substituídos pelos retuítes e os comentários pelas respostas a um determinado tuíte.
    
    % EQUAÇÃO
    \begin{equation} \label{eq:engajamento}
    E(x) = \frac{curtidas + compartilhamentos + coment\acute{a}rios}{seguidores}*100
    \end{equation}
    
    \par Apesar de existir esta convenção para o cálculo do engajamento, a fórmula pode variar, dependendo das informações fornecidas por cada rede social. Como por exemplo, no caso do Facebook, o total de seguidores pode ser substituído pelo total de visualizações obtidas por cada publicação, ou então, como também apresentado em \cite{pillat:17}, substituído pelo seguidores do próprio usuário mais os seguidores dos próprios fãs.

% % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % EXTRAÇÃO DOS TUÍTES % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Processamento dos Tuítes}
\label{sec:prop-processamento}

    \par Esta seção engloba a descrição e detalhamento dos processos envolvidos na arquitetura adotada, apresentada na Figura \ref{fig:arquitetura}, para realizar o processamento dos tuítes. Esta arquitetura contém os seguintes módulos principais: (a) \textbf{Coleta} dos tuítes publicados por cada uma das contas acompanhadas; (b) \textbf{Extração} das características de cada tuíte; e (c) \textbf{Atualização} periódica dos dados coletados.
    
    % IMAGEM
    \begin{figure}[ht]
        \caption{Arquitetura adotada para extração de tuítes}
        \centering
        \includegraphics[width=1\textwidth]{figuras/arquitetura.png}
        \vspace{\baselineskip} %%% linha em branco para atender a norma
        \fonte{Produção do próprio autor.}
        \label{fig:arquitetura}
    \end{figure}

% % % % % % % % COLETA DE TUÍTES % % % % % % % %

\subsection{Coleta dos Tuítes}
\label{sec:prop-coleta}

    \par O módulo de coleta é responsável por extrair tuítes de usuários específicos. A extração ocorre de forma contínua, usando recursos de \textit{streaming} disponibilizados pela API do Twitter \cite{site:twitter-api}. São coletados todos tuítes publicados a partir do momento que o \textit{streaming} entra em execução.
    
    \par A especificação das contas a serem seguidas é feita através de uma conta raiz, a partir da qual são extraídos os tuítes publicados por todos usuários seguidos por esta conta. Esta estratégia permite que novas contas sejam adicionadas à lista sem que haja interrupções na execução do algoritmo. O módulo também conta com tratamento de exceções para que a coleta não seja interrompida devido à problemas temporários de acesso aos dados, como indisponibilidade do serviço ou extrapolação do limite de requisições permitido por instante de tempo.
    
    \par Na Tabela \ref{tab:dados-coleta} podem ser visualizadas as informações extraídas de cada tuíte através da API. O campo ``mensagem'' é usado para a extração das características. Já os campos ``seguidores'', ``retuítes'' e ``curtidas'' são utilizados no cálculo para medir a taxa de engajamento de cada tuíte. Por sua vez, os campos ``identificação'' e ``data/hora'' são usados pelo módulo de atualização.
    
    % TABELA
    \begin{table}[ht]
    \centering
    \caption{Dados coletados para cada tuíte}
    \label{tab:dados-coleta}
    \begin{tabular}{|l|l|}
    \hline
    \textbf{Informação} & \textbf{Conteúdo} \\ \hline
    autor &  código e nome da conta que originou o tuíte \\ \hline
    seguidores &  quantidade de seguidores da conta que originou o tuíte \\ \hline
    identificação & código do tuíte (permite a consulta posterior) \\ \hline
    mensagem & texto de no máximo 280 caracteres \\ \hline
    data e hora & data e hora da publicação do tuíte em seu país de origem \\ \hline
    retuítes & quantidade de retuíte que a mensagem recebeu \\ \hline
    curtidas & quantidade de vezes que o tuíte foi favoritado \\ \hline
    \end{tabular}
    \end{table}
    
    \par Infelizmente a API do Twitter não permite a extração da quantidade de respostas à cada tuíte na versão gratuita, apenas na versão para assinantes, impossibilitando a contabilização desse valor na fórmula de engajamento. Desta forma, a Equação \ref{eq:engajamento}, para o cálculo da taxa de engajamento, apresentada na seção \ref{sec:prop-def-popularidade}, foi adaptada para considerar apenas as informações disponíveis, resultando na Equação \ref{eq:engajamento-api}. Tanto na versão original da fórmula, quanto a adaptação, o valor resultante é um percentual, podendo ser superior a 100\%. Esta particularidade é devida ao fato de que o número de iterações que um tuíte obtém pode ser maior que o total de seguidores da conta.
    
    % EQUAÇÃO
    \begin{equation} \label{eq:engajamento-api}
    E(x) = \frac{curtidas + retu\acute{\imath}tes}{seguidores}*100
    \end{equation}

% % % % % % % % EXTRAÇÃO DAS CARACTERÍSTICAS % % % % % % % %

\subsection{Extração dos Atributos}
\label{sec:prop-extracao}

    \par Esta etapa corresponde à extração das características de cada um dos tuítes coletados. A extração ocorre imediatamente após a coleta. Os itens abaixo mostram como cada característica foi extraída:
    
    \par \textbf{Presença de URLs e \textit{hashtags}}: O uso desses recursos na mensagem é facilmente detectado pela presença de prefixos específicos no corpo da mensagem. Por exemplo, o prefixo ``http'' indica que URLs foram usadas, enquanto que o prefixo ``\#'' denota o uso de \textit{hashtags}. 
    
    \par \textbf{Tamanho da mensagem}: O tamanho é extraído através da contagem da quantidade de caracteres presentes no texto. A contagem desconsidera caracteres usados em URLs, assumindo que \textit{hiperlinks} não transmitam nenhuma mensagem.  A remoção de URLs foi realizada a partir da aplicação de uma expressão regular.

    %%%%%%%%%%%%%%% EXTRAÇÃO DO SENTIMENTO %%%%%%%%%%%%%%%
    \par \textbf{Extração do sentimento:} Para realizar a extração do sentimento, foi utilizada a biblioteca TextBlob da linguagem Python \cite{loria:14}. Essa biblioteca  permite a obtenção da polaridade e subjetividade de conteúdos textuais na língua inglesa. A API também fornece a possibilidade de tradução do conteúdo de textos escritos em outras linguagens. A extração do sentimento realizada pela biblioteca se baseia em Árvores de Decisão e no modelo de classificação \textit{Naive Bayes} -- ambos já apresentados no Capítulo \ref{sec:fund-teorica} --, o que elimina a necessidade de elaborar no novo algoritmo para realizar essa função. 
    % assim como no trabalho de \cite{engel:16}

    %%%%%%%%%%%%%%% EXTRAÇÃO DA BANALIDADE %%%%%%%%%%%%%%%
    \par \textbf{Extração da banalidade:} A verificação da frequência utiliza um dicionário contendo 3000 palavras comuns da língua inglesa\footnote{\textit{3000 most common words in English: }\texttt{https://www.ef.com/english-resources/ english-vocabulary/top-3000-words/}}. Também são removidas as \textit{hashtags} e menções a outros usuários, por entender que não se tratam de palavras que podem ser caracterizadas como banais ou não.
    
    \par Na Tabela \ref{tab:dados-extracao} pode ser visto um exemplo geral de todas as caraterísticas extraídas nesta etapa.

    % TABELA
    \begin{table}[ht]
    \centering
    \caption{Dados obtidos na etapa de Extração}
    \label{tab:dados-extracao}
    \begin{tabular}{|l|l|}
    \hline
    \textbf{Informação} & \textbf{Conteúdo} \\ \hline
    sentimento & valor entre -1 e 1 correspondente a polaridade do texto \\ \hline
    URL & valor 1 se houver URL no texto e 0 se não houver \\ \hline
    \textit{hashtag} & valor 1 se houver \textit{hashtag} no texto e 0 se não houver \\ \hline
    tamanho & quantidade de caracteres utilizados na mensagem \\ \hline
    banalidade & somatório baseado na no uso de palavras frequentes \\ \hline
    \end{tabular}
    \end{table}


% % % % % % % % ATUALIZAÇÃO DOS DADOS % % % % % % % %

\subsection{Atualização dos Dados de Retuítes e Curtidas}
\label{sec:prop-atualizacao}

    \par Como o módulo de coleta funciona por meio de \textit{streaming}, os tuítes são coletados no instante de sua criação. Nesse momento, a quantidade de retuítes e curtidas recebidos têm o valor zero. Dessa forma, é necessária uma conferência periódica para a obtenção dos dados atualizados.
    
    \par A atualização é realizada através de um recurso da API do Twitter que obtém informações de um tuíte a partir do seu código de identificação. Para evitar sobrecarga de processamento, apenas os tuítes publicados no intervalo de 15 dias são atualizados. Como os dados de tuítes mais antigos raramente são modificados, a busca para a atualização de cada um deles seria ao mesmo tempo custosa e improdutiva.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % CLASSIFICAÇÃO DOS TUÍTES % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Classificação dos Tuítes}
\label{sec:prop-classificacao}

    \par Esta etapa descreve os processos e ferramentas utilizados na realização da classificação dos tuítes como populares ou não populares. Para a realização da predição dos tuítes tendo como base a taxa de engajamento e considerando os atributos já mencionados, serão utilizados os algoritmos de classificação já apresentados Naive Bayes e Árvores de decisão. Os experimentos com cada algoritmo são realizados através da implementação de código utilizando a linguagem de programação Python \cite{site:python} ou com o auxilio da ferramenta Weka \cite{site:weka}.
    
    \par A utilização da linguagem Python é justificada pela grande quantidade de bibliotecas que proporcionam maior facilidade em lidar com a manipulação de dados e aprendizado de máquina. Além disso, a linguagem conquistou grande popularidade dentre a comunidade que trabalha com inteligência artificial. Dentre estas bibliotecas, uma delas merece ser destacada aqui, que é a SciKit-Learn \cite{site:scikit-learn}, que consiste em um conjunto de funcionalidades específicas para trabalhar com diferentes modelos de aprendizado de máquina, dentre elas classificação, regressão, agrupamento, redução de dimensionalidade e pré-processamento.
    
    \par O Weka (sigla em inglês para \textit{Waikato Environment for Knowledge Analysis} e também nome de uma ave da Nova Zelândia) é uma ferramenta desenvolvida na linguagem Java que oferece um ambiente preparado para auxiliar no processo de análise e mineração de dados. Esse ambiente provê uma coleção de algoritmos capazes para realizar tarefas como preparação de dados, classificação, regressão, agrupamento, mineração de regras de associação e visualização \cite{site:weka}.

% % % % % % % % BALANCEAMENTO DAS INSTÂNCIAS % % % % % % % %

\subsection{Balanceamento das instâncias}
\label{sec:prop-class-balanceamento}
    
    \par Como apresentado em \cite{book:han:11}, a maioria dos modelos tradicionais de aprendizagem de máquina consideram que os dados de entrada já estão bem distribuídos dentre as classes, o que geralmente não acontece em bases de dados reais. Para resolver este problema, existem diversas técnicas para aperfeiçoar a classificação com dados desbalanceados. Duas destas técnicas são: \textit{oversampling}, que consiste no preenchimento dos dados da classe com menor número até que ambas sejam equivalentes; e o \textit{undersampling}, que consiste na redução dos dados da classe com o maior número \cite{kotsiantis:2006}.
    
    \par Desta forma, para realizar o treinamento e a validação dos dados, independente do modelo de aprendizagem aplicado, é importante que as entradas estejam bem distribuídas entre as classes. O desbalanceamento pode resultar em um modelo tendencioso, havendo a probabilidade de classificar os dados como uma determinada classe devido à predominância da mesma no momento do treinamento.

    \par Além do balanceamento, é preciso preparar a base de dados para cada teste, isto é, configurar os dados de entrada para cada modelo considerando a taxa de engajamento e o usuário autor dos tuítes. Para realizar este processo, foi elaborado uma algoritmo que realiza o \textit{undersampling} considerando uma determinada taxa de engajamento e usuário passados por parâmetro. Este processo também foi escrito na linguagem Python e uma versão simplificada, em pseudo código, pode ser vista logo abaixo no Algoritmo \ref{alg:get-data}.
    
    % ALGORITMO
    \begin{algorithm}[ht]
    \caption{Algoritmo para preparação dos dados}
    \label{alg:get-data}
    \begin{algorithmic}[1]
    \Function{preparaDados}{$taxa$, $autor = 0$}
        \State $tuites \gets embaralha(buscaListaDeTuites(taxa, autor))$
        \State 
        \State $max \gets maximoPorClasse(tuites)$
        \State $nPop, nNaoPop \gets 0, 0$
        \State $dados, classes \gets [$ $], [$ $]$
        \State
        \For{each $tw$ in $tuites$}
            \If{($nPop$ == $max$ $E$ $tw['pop']$) $OU$ ($nNaoPop$ == $max$ $E$ !$tw['pop']$)}
                \State \textit{pular}
            \EndIf
            %\State 
            \State $dados.novo(tw['atributos'])$
            \State $classes.novo(tw['pop'])$
            %\State
            \If{$tw['popular']$}
                \State $nPop \gets nPop + 1$
            \Else
                \State $nNaoPop \gets nNaoPop + 1$
            \EndIf
            %\State
            \If{$quantidade(dados)$ == $max*2$}
                \State \textit{parar}
            \EndIf
        \EndFor
        \State \textbf{return} $dados, classes$
        \EndFunction
    \end{algorithmic}
    \end{algorithm}
    
    \par O algoritmo tem como entrada a taxa de engajamento e o código do usuário, que pode não ser informado, para o caso de análises gerais. Como primeira instrução, é feita uma busca pelos tuítes considerando a taxa e o usuário. Neste momento também é feito o embaralhamento dos dados, garantindo que a ordem dos registros não seja determinante nos resultados de cada execução. A própria função de busca faz o tratamento da necessidade de distinção dos dados por usuário. Tento a lista completa, é identificada a classe que possui o menor número de registros, sendo esta a variável responsável pelo balanceamento. 
    
    \par Após identificar o número máximo de instâncias por classe, são inicializadas as variáveis de controle (\textit{nPop} e \textit{nNaoPop}), \textit{dados} e \textit{classes}. Em seguida é feito um laço de repetição para cada tuíte. Para cada iteração do laço é feita uma verificação da quantidade de entradas em cada classe através das variáveis de controle e, se o valor for menor que o máximo, os atributos e classe são guardados. Por fim, as variáveis de controle são incrementadas. O laço termina quando a quantidade de dados alcança o valor máximo, retornando então as listas balanceadas. Para ilustrar o funcionamento desse algoritmo, foi elaborada a Figura \ref{fig:balanceamento}, apresentada logo abaixo.
    
    \par A figura apresenta a entrada de dois parâmetros, \textit{x} e \textit{u}, sendo respectivamente a taxa de engajamento e o usuário. Então o módulo de preparação dos dados faz a consulta, a contagem da quantidade de dados por classe, sendo \textit{n} a quantidade menor e então faz a separação dos dados, devolvendo \textit{2n} registros, distinguindo atributos de classes. Esta representação, assim como o código descrito no Algoritmo \ref{alg:get-data}, é uma versão simplificada do processamento real. %Há ainda o trecho responsável pela geração do arquivo para utilização no Weka, se necessário for. O formato deste arquivo gerado pelo código e aceito pela ferramenta é o ARFF (sigla em inglês para \textit{Attribute-Relation File Format}).
    
    % IMAGEM
    \begin{figure}[H]
        \caption{Processo de balanceamento}
        \centering
        \includegraphics[width=1\textwidth]{figuras/balanceamento.png}
        \vspace{\baselineskip} %%% linha em branco para atender a norma
        \fonte{Produção do próprio autor.}
        \label{fig:balanceamento}
    \end{figure}

% % % % % % MÉTODOS CLASSIFICAÇÃO UTILIZADOS % % % % % %

\subsection{Métodos de Classificação Utilizados}
\label{sec:prop-class-metodos}

    \par Os processos de classificação dos dados foram divididos em dois tipos: utilizando somente o texto pré-processado dos tuítes e utilizando os atributos obtidos de cada tuíte na etapa de extração, descrita na subseção \ref{sec:prop-extracao}. Os experimentos considerando o texto foram realizados via código em Python, enquanto que os experimentos considerando os atributos foram realizados utilizando a ferramenta Weka. Apesar de realizados em duas vertentes, independente do algoritmo, é realizado o processo de balanceamento descrito anteriormente.
    
    \par Para a estratégia utilizando o texto pré-processado, é utilizado o algoritmo Naive Bayes, por sua grande popularidade no processamento de conteúdo escrito. O algoritmo para este modelo foi implementado utilizando a linguagem Python, com o auxílio da biblioteca para aprendizado de máquina Scikit-Learn. O algoritmo é baseado em cálculos probabilísticos conforme apresentado na seção \ref{sec:fund-naive-bayes} e, assim como código de balanceamento exposto, também recebe como parâmetros de entrada a taxa de engajamento e o usuário autor. Ao final da execução, como retorno são apresentadas as métricas de avaliação do modelo, juntamente com a matriz de confusão. Esse formato de saída foi adotado com o intuito de manter a consistência com os resultados obtidos a partir dos testes utilizando o Weka.
    
    \par No caso da estratégia utilizando utilizando os atributos coletados, também é utilizado o Naive Bayes, além árvores de decisão, focando nos modelos J48 e LTM (sigla para \textit{Logistic Model Trees}). Para todos estes casos, optou-se pela realização dos testes utilizando o Weka, devido sua praticidade em realizar o treinamento e validação dos dados a partir de arquivos.
    
    \par A geração destes arquivos de entrada para o Weka é feita de maneira automatizada, a partir de um módulo agregado ao algoritmo de balanceamento, que têm como saída um arquivo do tipo ARFF. Como conteúdo do mesmo, além dos próprios dados, são descritos os atributos utilizados e seus tipos. Cada arquivo, que tem como variante a taxa de engajamento e o usuário, é carregado na ferramenta e aplicado para cada um dos três algoritmos. Com os resultados de cada execução, são gerados gráficos para uma análise visual do desempenho de cada modelo. As análises mais significativas são mostradas no Capítulo \ref{sec:experimentos} a seguir.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % METODOLOGIA  % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\begin{comment}
\chapter{Metodologia}
\label{sec:metodologia}

    \par Para alcançar os objetivos elencados, uma série de etapas foi elaborada para a realização deste projeto, nas quais o sucesso de uma está diretamente ligado ao da outra. A fim de proporcionar maior compreensão destas etapas, este capítulo foi destinado à descrição de cada uma destas etapas juntamente com a apresentação do cronograma do projeto, no qual consta a previsão de realização de cada uma delas.
    
    \par \textbf{Análise de trabalhos similares:} Nesta etapa será realizada uma pesquisa sobre trabalhos similares já realizados na área envolvendo aprendizado de máquina e extração de dados extraídos do Twitter, com o objetivo de que os mesmos possam vir a auxiliar e contribuir com a proposta do trabalho.
    
    \par \textbf{Definição dos atributos:} Esta etapa é designada para analisar e definir quais serão os atributos de interesse que devem ser extraídos de cada tuíte, considerando a relevância que cada um deles pode inferir sobre a popularidade daquele tuíte.
    
    \par \textbf{Extração e pré-processamento dos dados:} Dispondo dos atributos de interesse, os tuítes devem ser coletados e seus conteúdos pré-processados. Para isso, será realizado um estudo acerca dos melhores métodos e ferramentas que permitem a extração de dados do Twitter e posteriormente de seus atributos de interesse.
    
    \par \textbf{Estudo de algoritmos de aprendizado de máquina:} Estando em posse dos dados já processados, será realizado um estudo acerca dos algoritmos de aprendizado de máquina para classificação de dados e quais são as melhores opções considerando os dados de entrada e os atributos de interesse.
    
    \par \textbf{Implementação dos algoritmos:} Dispondo do conhecimento necessário acerca algoritmos de aprendizado de máquina e os atributos disponíveis, serão implementados tais algoritmos utilizando tecnologias adequadas para tal.
    
    \par \textbf{Experimentos com os algoritmos selecionados:} Esta etapa corresponde a realização de testes com os algoritmos estudados e implementados nas etapas anteriore. O experimentos serão realizados com o objetivo de classificar a popularidade dos tuítes com base nos atributos extraídos.
    
    \par \textbf{Análise dos resultados obtidos:} Esta etapa do trabalho destina-se a realização de uma análise sobre os algoritmos testados e os resultados obtidos com cada um deles ao tentar realizar a predição da popularidade dos tuítes.
    
    \par \textbf{Documentação:} Por fim, é nesta etapa que os resultados obtidos com o decorrer do projeto são analisados e documentados, havendo a chance de originar um artigo, considerando que houve certa contribuição científica com a área, além do próprio relatório do Trabalho de Conclusão de Curso.
    
    \section{Cronograma}
    
    \par Com base nas etapas descritas, a Tabela \ref{tab:cronograma} a seguir resume o cronograma das atividades previstas. Dividido entre quinzenas, o cronograma tem início a partir do mês de Agosto (08). As atividades já realizadas até o momento compreendem os itens marcados com bola ($\bullet$) e fundo em cinza, enquanto que os marcadores em xis ($\times$) com fundo branco representam as atividades que ainda devem ser realizadas.
    
    \begin{table}[ht]
    \centering
    \caption{Cronograma do projeto}
    \label{tab:cronograma}
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|}
    \hline
    \textbf{Atividade} & \textbf{8/2} & \textbf{9/1} & \textbf{9/2} & \textbf{10/1} & \textbf{10/2} & \textbf{11/1} & \textbf{11/2} & \textbf{12/1} \\ \hline
    Análise de trabalhos similares & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$  &  &  &  &  &  &  \\ \hline
    Definição dos Atributos & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ &  &  &  &  &  \\ \hline
    Extração e pré-processamento &  & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ &  &  &  \\ \hline
    Estudo de algoritmos de IA &  &  &  & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ &  &  \\ \hline
    Implementação dos algoritmos &  &  &  & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & $\times$ & $\times$ & $\times$ \\ \hline
    Experimentos com algoritmos &  &  &  & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & $\times$ & $\times$ & $\times$ \\ \hline
    Análise dos resultados obtidos &  &  &  &  &  & $\times$ & $\times$ & $\times$ \\ \hline
    Documentação & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & \cellcolor{gray!20}$\bullet$ & $\times$ & $\times$ & $\times$ \\ \hline
    \end{tabular}
    \end{table}
\end{comment}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % EXPERIMENTOS  % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\chapter{Experimentos}
\label{sec:experimentos}

    \par Este capítulo apresenta os experimentos realizados e resultados obtidos com a aplicação dos algoritmos Naive Bayes e árvores de decisão sobre os dados coletados a partir da plataforma do Twitter. De maneira geral, os experimentos têm por objetivo realizar análises, variando o usuário e a taxa de engajamento, para classificar os tuítes como populares ou não. O intuito é identificar uma possível correlação entre estas variantes e as características extraídas de cada tuítes.

% % % % % % % % DADOS COLETADOS % % % % % % % %

\section{Dados Coletados}
\label{sec:exp-dados-coletados}

    \par Com relação aos processos envolvendo a coleta dos dados, explanados na seção \ref{sec:prop-processamento}, eles foram realizados a partir do monitoramento das contas de personalidades influentes que utilizam o Twitter periodicamente. Ao todo, foram consideradas 30 contas de diversas áreas de atuação, como por exemplo Donald J. Trump (atual presidente dos Estados Unidos), Jimmy Fallon (apresentador de TV americano), Katy Perry (cantora detentora da conta com o maior número de seguidores no Twitter) e diversas empresas influentes.
    
    \par A escolha deve-se ao fato de que a análise do impacto de publicações em redes sociais é mais relevante para esse tipo de usuário, uma vez o cálculo da taxa de engajamento para contas com poucos seguidores resultaria sempre em um valor próximo a zero. O que também é reforçado por \cite{ieee:suh:10}, quanto maior a audiência, maiores são as chances de um tuíte ser retuitado. A coleta dos tuítes foi realizada o mês de novembro de 2017 e maio de 2018, totalizando cerca de 8600 registros distribuídos entre as contas de interesse que foram escritos na língua inglesa. A seguir, na Tabela \ref{tab:contas-tweets}, pode ser observado o total de dados extraídos dos usuários com maior número tuítes, a versão completa pode ser observada no Anexo \ref{anexo-tebela-contas}
    % período entre Novembro de 2017 e Setembro de 2018
    
    \begin{table}[ht]
    \centering
    \caption{Dados coletados por conta}
    \label{tab:contas-tweets}
    \begin{tabular}{|l|r|r|r|r|}
    \hline
    \textbf{Conta}  & \multicolumn{1}{l|}{\textbf{Tuítes}} & \multicolumn{1}{l|}{\textbf{Retuítes}} & \multicolumn{1}{l|}{\textbf{Curtidas}} & \multicolumn{1}{l|}{\textbf{Seguidores}} \\ \hline
    Alex Jones      & 4,672  & 1,930,401     & 620,015     & 817,779     \\ \hline
    Ellen DeGeneres & 822    & 2,653,308     & 7,886,125   & 7,796,6272  \\ \hline
    Donald J. Trump & 701    & 15,034,127    & 62,231,949  & 51,954,765  \\ \hline
    NASA            & 613    & 568,676       & 1,631,924   & 29,550,297  \\ \hline
    Jimmy Fallon    & 353    & 316,448       & 1,314,721   & 51,164,006  \\ \hline
    Katy Perry      & 227    & 939,573       & 2,203,336   & 109,563,129 \\ \hline
    \end{tabular}
    \end{table}
    
% % % % % % % % MÉTRICAS % % % % % % % %

\section{Métricas de Avaliação}
\label{sec:exp-class-metricas}

    \par A fim de realizar a avaliação dos modelos de avaliação, é importante que sejam definidas as métricas utilizadas na comparação entre os modelos. Para isso, serão consideradas cinco métricas: acurácia; sensibilidade; especificidade; valor preditivo positivo; e valor preditivo negativo. Estas medidas, apresentadas respectivamente nas equações \ref{eq:acuracidade}, \ref{eq:sensibilidade}, \ref{eq:especificidade} e \ref{eq:predit-pos}, retiradas e traduzidas de \cite{book:han:11}, são aplicadas após a etapa de validação. Elas consideram os acertos e erros do algoritmo sobre cada uma das classes em relação ao total de cada classe.
    
    \par A \textbf{acurácia} é uma medida de análise geral dos acertos, sem diferenciação entre as classes. Já a \textbf{sensibilidade} e a \textbf{especificidade} são as medidas que indicam a capacidade do modelo em realizar a predição das entradas como a classe positiva e negativa, respectivamente. Por sua vez, os valores \textbf{preditivos}, expressam a relação do total de predições corretas de uma das classes com o total de predições realizadas para essa mesma classe. As formulas de valor preditivo negativo e positivo, assim como a sensibilidade e especificidade, são equivalentes, variando apenas a classe em questão.
    
    % EQUAÇÃO
    \begin{equation} \label{eq:acuracidade}
    Acur\acute{a}cia = \frac{AcertosPositivos + AcertosNegativos}{TotalPositivos + TotalNegativos}
    \end{equation}
    
    % EQUAÇÃO
    \begin{equation} \label{eq:sensibilidade}
    Sensibilidade = \frac{AcertosPositivos}{TotalPositivos}
    \end{equation}
    
    % EQUAÇÃO
    \begin{equation} \label{eq:especificidade}
    Especificidade = \frac{AcertosNegativos}{TotalNegativos}
    \end{equation}
    
    % EQUAÇÃO
    \begin{equation} \label{eq:predit-pos}
    PreditivoPositivo = \frac{AcertosPositivos}{AcertosPositivos + FalsosPositivos}
    \end{equation}
    
    % EQUAÇÃO
    \begin{equation} \label{eq:predit-neg}
    PreditivoNegativo = \frac{AcertosNegativos}{AcertosNegativos + FalsosNegativos}
    \end{equation}
    
    \par Apesar da importância da utilização de todas as métricas apresentadas, destacam-se duas delas: a acurácia e a sensibilidade. A acurácia por expressar o acerto do modelo de maneira geral, e a sensibilidade por expressar o acerto do modelo sobre a classe de interesse, que é o caso de um tuíte ser popular. Desta forma, pode-se estabelecer como prioridade a otimização dos resultados obtidos nestas medidas.
    
% % % % % % % % RELAÇÃO ENTRE ENGAJAMENTO E BALANCEAMENTO % % % % % % % %

\section{Relação entre Engajamento e Balanceamento}
\label{sec:exp-engaj-balanc}

    \par No intuito de analisar a relação entre a quantidade de instâncias balanceadas para cada classe e a variação da taxa de engajamento, foi elaborado o gráfico da Figura \ref{tik:engaj-balanc}. Para melhorar a visualização das demarcações entre as contas, as quantidades foram normalizadas, assumindo como 100\% os valores que maximizam a distribuição de dados por classes. No gráfico constam quatro curvas, referentes três contas, escolhidas por estarem entre aquelas com o maior número de mensagens publicadas, e a quarta é referente à análise geral. As curvas são definidas por: 
    
    \begin{itemize}
        \item \textbf{Dados gerais:} tracejado em azul, com marcadores no formato de triângulo;
        \item \textbf{Donald J. Trump:} em vermelho, com marcadores no formato de losango;
        \item \textbf{Ellen DeGeneres:} em verde, com marcadores no formato de quadrado;
        \item \textbf{Alex Jones:} em amarelo, com marcadores no formato de bola.
    \end{itemize}
    
    \begin{figure}[!ht]
    \caption{Número de instâncias balanceadas por taxa de engajamento.}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\textwidth,
            height=.5\textwidth,
            symbolic x coords={0.2\%, 0.5\%, 1\%, 2\%, 3\%, 4\%, 10\%, 20\%, 22\%, 25\%},
            xtick=data,
        ]
            \addplot[mark=triangle*, mark size=4, draw=myblue,  mark options={solid}, myblue, thick, dashed] coordinates {
                (0.2\%, 0.336) (0.5\%, 0.528) (1\%, 0.727) (2\%, 1.000) (3\%, 0.772) (4\%, 0.715) (10\%, 0.394) (20\%, 0.234) (22\%, 0.206) (25\%, 0.169)
            }node[pos=0.8,above,anchor=north west]{Geral};
            
            \addplot[mark=diamond*, mark size=3, draw=myred, thick, myred] coordinates {
                (0.2\%, 0.035) (0.5\%, 0.038) (1\%, 0.041) (2\%, 0.061) (3\%, 0.102) (4\%, 0.122) (10\%, 0.177) (20\%, 0.794) (22\%, 1.000) (25\%, 0.756)
            }node[pos=0.7,above,anchor=north west]{Donald J. Trump};
            
            \addplot[mark=square*, mark size=2, draw=ForestGreen, thick, ForestGreen] coordinates {
                (0.2\%, 0.258) (0.5\%, 1.000) (1\%, 0.647) (2\%, 0.331) (3\%, 0.236) (4\%, 0.175) (10\%, 0.053) (20\%, 0.020) (22\%, 0.015) (25\%, 0.013)
            }node[pos=0.7,above,anchor=north west]{Ellen DeGeneres};

            \addplot[mark=*, mark size=2, draw=YellowOrange, thick, YellowOrange] coordinates {
                (0.2\%, 0.446) (0.5\%, 0.482) (1\%, 0.607) (2\%, 0.943) (3\%, 1.000) (4\%, 0.789) (10\%, 0.296) (20\%, 0.130) (22\%, 0.116) (25\%, 0.100)
            }node[pos=0.8,above,anchor=north west]{Alex Jones};

        \end{axis}
    \end{tikzpicture}
    \fonte{Produção do próprio autor.}
    \label{tik:engaj-balanc}
    \end{figure}
    
    \par O foco da análise neste gráfico, é a observação dos pontos em que a taxa de engajamento maximiza o número de instâncias balanceadas, isto é, o maior número possível de dados distribuídos entre as classes. No gráfico, isso é expressado pelo eixo \textit{y}, de forma que quanto mais próximo de um, maior é o aproveitamento dos dados de cada conta.
    
    \par A primeira coisa que pode ser observada, no caso da curva ''Geral``, é que o valor ótimo para maximizar o número de dados balanceados é de 2\%, e para cada uma das demais curvas, o pico é determinado por taxas de engajamento diferentes. Esse fator reforça o propósito da aplicação dos modelos considerando contas individualizadas, já que a taxa de engajamento ideal para um usuário, pode não ser a mesma para os demais. Pode-se observar também que a variação desta taxa, para qualquer direção, resulta em uma perda de dados considerável, padrão que também se aplica aos demais casos.
    
% % % % % % % % ANÁLISE GENERALIZADA DAS CONTAS % % % % % % % %

\section{Análise Generalizada das Contas}
\label{sec:exp-analise-geral}
    
    \par Nesta seção, são considerados os tuítes publicados por qualquer uma das contas contidas na base de dados. Os testes foram realizados para medir do desempenho dos diferentes modelos de aprendizagem de máquina supervisionada em função das métricas. O primeiro teste realizado, exposto no gráfico da Figura \ref{tik:acuracia-geral}, apresenta a variação da acurácia de cada um dos quatro modelos conforme a taxa de engajamento é modificada.
    
    % DADOS 215
    \pgfplotstableread[row sep=\\,col sep=&]{
        algorithm       & tx010 & tx020 & tx030 & tx040 & tx100 & tx200 \\
        NBayesTexto     & 0.658 & 0.681 & 0.670 & 0.662 & 0.674 & 0.679 \\
        NBayesAtributos & 0.631 & 0.617 & 0.610 & 0.603 & 0.564 & 0.606 \\
        J48             & 0.637 & 0.619 & 0.607 & 0.604 & 0.579 & 0.651 \\
        LMT             & 0.634 & 0.615 & 0.609 & 0.598 & 0.596 & 0.641 \\
        }\mydata
    
    % GRÁFICO ---------------------- ACURÁCIA
    \begin{figure}[!ht]
    \caption{Acurácia de cada algoritmo aplicado sobre toda a base com diferentes taxas de engajamento.}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                ybar,
                enlarge x limits={abs=1.75cm},
                bar width=0.42cm,
                width=\textwidth,
                height=.5\textwidth,
                legend style={at={(0.5,1)},
                    anchor=north,legend columns=-1},
                symbolic x coords={NBayesTexto, NBayesAtributos, J48, LMT},
                xtick=data,
                %nodes near coords,
                %nodes near coords align={vertical},
                ymin=0.55,ymax=0.71,
                ylabel={acurácia},
                legend image code/.code={%
                   \draw[#1, draw=none] (0cm,-0.2cm) rectangle (0.44cm,0.2cm);
                },
            ]
            \addplot [fill=myblue!75,postaction={pattern=north east lines, pattern color=Blue}] table[x=algorithm,y=tx010]{\mydata};
            
            \addplot [fill=myred!70,postaction={pattern=horizontal lines, pattern color=Mahogany}] table[x=algorithm,y=tx020]{\mydata};
            
            \addplot [fill=YellowOrange,postaction={pattern=vertical lines, pattern color=Yellow}] table[x=algorithm,y=tx030]{\mydata};
            
            \addplot [fill=ForestGreen,postaction={pattern=north east lines, pattern color=SkyBlue}] table[x=algorithm,y=tx040]{\mydata};
            
            \addplot [fill=Orange,postaction={pattern=dots, pattern color=Goldenrod}] table[x=algorithm,y=tx100]{\mydata};
            
            \addplot [fill=Aquamarine,postaction={pattern=horizontal lines, pattern color=white}] table[x=algorithm,y=tx200]{\mydata};
            
            \legend{1.0\%, 2.0\%, 3.0\%, 4.0\%, 10.0\%, 20.0\%}
        \end{axis}
    \end{tikzpicture}
    \fonte{Produção do próprio autor.}
    \label{tik:acuracia-geral}
    \end{figure}
    
    \par É possível identificar que o algoritmo Naive Bayes aplicado ao texto apresentou resultados melhores em relação aos demais, que foram aplicados utilizando os atributos extraídos de cada mensagem. O melhor resultado obtido neste modelo foi com a taxa de engajamento de 2\%, que alcançou 68.1\% de acurácia. Nos demais algoritmos, os resultados variam entre 56.4\%  e 65,1\%.

    \par Ainda realizando a análise geral sobre os dados de todas as contas, foi elaborado o gráfico da Figura \ref{tik:sensibilidade-geral}. Neste caso, é exposta a variação no valor da sensibilidade para cada algoritmo, também considerando a modificação na taxa de engajamento. Novamente, apesar de intervalos muito próximos, nota-se que o modelo Naive Bayes aplicado ao texto obteve resultados ligeiramente melhores que os demais modelos, que foram aplicados sobre os atributos. Também é possível observar que o algoritmo aplicado ao texto apresenta resultados que melhoram -- dentro do espectro testado -- conforme aumenta a taxa de engajamento. Isso mostra que esse modelo pode ter um comportamento mais previsível que os demais.
    
    % DADOS
    \pgfplotstableread[row sep=\\,col sep=&]{
        algorithm       & tx010 & tx020 & tx030 & tx040 & tx100 & tx200 \\
        NBayesTexto     & 0.742 & 0.764 & 0.789 & 0.784 & 0.867 & 0.885 \\
        NBayesAtributos & 0.718 & 0.727 & 0.769 & 0.773 & 0.472 & 0.597 \\
        J48             & 0.662 & 0.704 & 0.660 & 0.680 & 0.485 & 0.597 \\
        LMT             & 0.693 & 0.688 & 0.736 & 0.755 & 0.549 & 0.605 \\
        }\mydata
    
    % GRÁFICO ---------------------- SENSIBILIDADE
    \begin{figure}[!ht]
    \caption{Sensibilidade de cada algoritmo aplicado sobre toda a base com diferentes taxas de engajamento.}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                ybar,
                enlarge x limits={abs=1.75cm},
                bar width=0.42cm,
                width=\textwidth,
                height=.5\textwidth,
                legend style={at={(0.5,1)},
                    anchor=north,legend columns=-1},
                symbolic x coords={NBayesTexto, NBayesAtributos, J48, LMT},
                xtick=data,
                %nodes near coords,
                %nodes near coords align={vertical},
                ymin=0.40,ymax=0.96,
                ylabel={sensibilidade},
                legend image code/.code={%
                   \draw[#1, draw=none] (0cm,-0.2cm) rectangle (0.44cm,0.2cm);
                },
            ]
            \addplot [fill=myblue!75,postaction={pattern=north east lines, pattern color=Blue}] table[x=algorithm,y=tx010]{\mydata};
            
            \addplot [fill=myred!70,postaction={pattern=horizontal lines, pattern color=Mahogany}] table[x=algorithm,y=tx020]{\mydata};
            
            \addplot [fill=YellowOrange,postaction={pattern=vertical lines, pattern color=Yellow}] table[x=algorithm,y=tx030]{\mydata};
            
            \addplot [fill=ForestGreen,postaction={pattern=north east lines, pattern color=SkyBlue}] table[x=algorithm,y=tx040]{\mydata};
            
            \addplot [fill=Orange,postaction={pattern=dots, pattern color=Goldenrod}] table[x=algorithm,y=tx100]{\mydata};
            
            \addplot [fill=Aquamarine,postaction={pattern=horizontal lines, pattern color=white}] table[x=algorithm,y=tx200]{\mydata};
            
            \legend{1.0\%, 2.0\%, 3.0\%, 4.0\%, 10.0\%, 20.0\%}
        \end{axis}
    \end{tikzpicture}
    \fonte{Produção do próprio autor.}
    \label{tik:sensibilidade-geral}
    \end{figure}
    
    \par Com o objetivo de tentar identificar uma possível relação entre a variação no número de instâncias e as métricas de acurácia, sensibilidade e especificidade, foi elaborado o gráfico da Figura \ref{tik:balanc-metricas}, exibido logo abaixo. Neste caso, foram delineadas as curvas de cada medida apenas para o modelo Naive Bayes aplicado ao texto, além da própria curva do balanceamento das instâncias -- também normalizado, assim como no gráfico \ref{tik:engaj-balanc}. 

    \begin{figure}[ht]
    \caption{Variação no número de instâncias em relação às métricas para o algoritmo Naive Bayes utilizando o texto.}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\textwidth,
            symbolic x coords={1.0\%, 2.0\%, 3.0\%, 4.0\%, 10.0\%, 20.0\%},
            xtick=data,
            %ymin=0.55,ymax=0.71,
        ]
            
            \addplot[mark=triangle*, mark size=4, draw=myblue,  mark options={solid}, myblue, thick, dashed] coordinates {
                (1.0\%, 0.727) (2.0\%, 1.000) (3.0\%, 0.772) (4.0\%, 0.715) (10.0\%, 0.394) (20.0\%, 0.187)
            }node[pos=0.3,above,anchor=south west]{Balanceamento};
            
            \addplot[mark=diamond*, mark size=5, draw=myred, thick, myred] coordinates { 
                (1.0\%, 0.658) (2.0\%, 0.681) (3.0\%, 0.670) (4.0\%, 0.662) (10.0\%, 0.674) (20.0\%, 0.679)
            }node[pos=0.7,above,anchor=north west]{Acurácia};
            
            \addplot[mark=square*, mark size=3, draw=ForestGreen, thick, ForestGreen] coordinates { 
                (1.0\%, 0.742) (2.0\%, 0.764) (3.0\%, 0.789) (4.0\%, 0.784) (10.0\%, 0.867) (20.0\%, 0.885)
            }node[pos=0.7,above,anchor=north west]{Sensibilidade};
            
            \addplot[mark=*, mark size=4, draw=YellowOrange, thick, YellowOrange] coordinates { 
                (1.0\%, 0.577) (2.0\%, 0.599) (3.0\%, 0.551) (4.0\%, 0.539) (10.0\%, 0.487) (20.0\%, 0.474)
            }node[pos=0.4,above,anchor=north]{Especificidade};
        \end{axis}
    \end{tikzpicture}
    \fonte{Produção do próprio autor.}
    \label{tik:balanc-metricas}
    \end{figure}
    
    \par Observa-se inicialmente, que não há uma relação nítida entre as curvas, porém, isso pode ser atribuído ao fato de que a variação no intervalo das métricas é muito pequeno. Apesar disso, considerando também o gráfico \ref{tik:acuracia-geral}, pode-se notar que a melhor acurácia, também é aquela que maximiza o balanceamento entre as classes. O mesmo padrão não se aplica ao caso da sensibilidade, que aparentemente tem a tendência de aumentar, conforme o número de instâncias é reduzido. Em contrapartida, a curva de especificidade aparentemente tem a melhor relação com o balanceamento das instâncias, já que também tem como pico a taxa de 2\% e tende a diminuir na mesma proporção ao variar a taxa para qualquer direção.
    
% % % % % % % % ANÁLISE DAS CONTAS GERAIS % % % % % % % %

\section{Análise Individualizada das Contas}
\label{sec:exp-analise-individual}

    \par Para a realização dos processos de treinamento e validação dos dados utilizando o aprendizado de máquina, torna-se extremamente importante a utilização de uma quantidade de registros consideravelmente grande. Isso deve-se a dificuldade em fazer estimativas quando se tem poucos dados disponíveis. Nos casos em que isto ocorre, a simples ordenação dos dados pode influenciar na predição final dos algoritmos, já que cada entrada representa uma porcentagem relativamente grande de toda a base disponível. A utilização de poucos dados de entrada faz com que os valores das métricas sejam variáveis para cada execução dos algoritmos.

    \par Devido a esse fator, diferentemente dos experimentos realizados na seção anterior, os testes individualizados serão realizados considerando apenas a taxa de engajamento que maximiza a quantidade de registros distribuídos dentre as classes. Caso fossem utilizadas outras taxas de engajamento, ocorreria uma grande perda dos registros, devido a realizado do \textit{undersampling}. Esse fato é reforçado pelo gráfico da Figura \ref{tik:engaj-balanc}, que apresenta a análise da relação entre a taxa de engajamento e o balanceamento das instâncias. 
    
    \par Ainda em função da quantidade de dados, a escolha das contas para realização dos testes nesta etapa foi feita considerando o número de mensagens publicadas por cada uma delas e, assim como na seção \ref{sec:exp-engaj-balanc}, foram escolhidas as três contas de usuários com o maior número de tuítes capturados, sendo eles: Donald J. Trump, Ellen DeGeneres e Alex Jones. Na sequência são apresentados os gráficos \ref{tik:acuracia-individual} e \ref{tik:sensibilidade-individual}, que contém os valores obtidos, respectivamente, de acurácia e sensibilidade com cada um dos algoritmos aplicadas sobre os tuítes destas três contas.
    
    \par Os resultados encontrados nestes casos não foram realmente satisfatórios, conforme o esperado da análise de contas individualmente. De maneira geral, os dados demonstram uma acurácia inferior em relação aos modelos utilizando todas as contas da base. Esse fator pode ser atribuído à quantidade de dados disponíveis para cada conta de usuário. Análises mais completas devem ser realizadas, utilizando uma quantidade consideravelmente maior de tuítes por conta, para assegurar se o mesmo padrão se mantém ou se a acurácia dos modelos é, de fato, inferior quando aplicados sobre contas individuais.
    
    % DADOS
    \pgfplotstableread[row sep=\\,col sep=&]{
        account       	& NBT 	& NBA 	& J48 	& LMT \\
        Donald J. Trump & 0.557 & 0.615 & 0.625 & 0.611 \\
        Ellen DeGeneres & 0.617 & 0.596 & 0.558 & 0.561 \\
        Alex Jones      & 0.618 & 0.655 & 0.662 & 0.662 \\
        }\mydata
    
    % GRÁFICO ---------------------- ACURÁCIA
    \begin{figure}[!ht]
    \caption{Acurácia dos algoritmos utilizando contas individualizadas.}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                ybar,
                enlarge x limits={abs=2.5cm},
                bar width=0.65cm,
                width=\textwidth,
                height=.5\textwidth,
                legend style={at={(0.5,1)},
                    anchor=north,legend columns=-1},
                symbolic x coords={Donald J. Trump, Ellen DeGeneres, Alex Jones},
                xtick=data,
                %nodes near coords,
                %nodes near coords align={vertical},
                ymin=0.55,ymax=0.68,
                ylabel={acurácia},
                legend image code/.code={%
                   \draw[#1, draw=none] (0cm,-0.2cm) rectangle (0.44cm,0.2cm);
                },
            ]
            \addplot [fill=myblue!75,postaction={pattern=north east lines, pattern color=Blue}] table[x=account,y=NBT]{\mydata};
            
            \addplot [fill=myred!70,postaction={pattern=horizontal lines, pattern color=Mahogany}] table[x=account,y=NBA]{\mydata};
            
            \addplot [fill=YellowOrange,postaction={pattern=vertical lines, pattern color=Yellow}] table[x=account,y=J48]{\mydata};
            
            \addplot [fill=ForestGreen,postaction={pattern=north east lines, pattern color=SkyBlue}] table[x=account,y=LMT]{\mydata};
            
            \legend{NBayesTexto, NBayesAtributos, J48, LMT}
        \end{axis}
    \end{tikzpicture}
    \fonte{Produção do próprio autor.}
    \label{tik:acuracia-individual}
    \end{figure}
    
    \par Apesar de incipientes e um pouco inferiores aos resultados gerais, os gráficos mostram que há relevância na realização das análises individualizadas. Pode-se observar que para cada uma das contas comparadas, não há um padrão entre valores obtidos com cada algoritmo e ainda, para cada caso, um modelo diferente obteve a melhor acurácia. Isso mostra que cada usuário pode ter suas especificidades e dependendo disso, um determinado algoritmo pode se sobressair em relação aos demais. Enquanto que para a conta de Donald Trump o Naive Bayes aplicado ao texto obteve a pior acurácia, o mesmo modelo aplicado sobre a conta de Ellen DeGeneres, obteve o melhor valor referente à mesma métrica.
    
    % DADOS
    \pgfplotstableread[row sep=\\,col sep=&]{
        account       	& NBT 	& NBA 	& J48 	& LTM \\
        Donald J. Trump & 0.814 & 0.795 & 0.625 & 0.611 \\
        Ellen DeGeneres & 0.499 & 0.494 & 0.430 & 0.544 \\
        Alex Jones      & 0.744 & 0.681 & 0.664 & 0.664 \\
        }\mydata
    
    % GRÁFICO ---------------------- ACURÁCIA
    \begin{figure}[!ht]
    \caption{Sensibilidade dos algoritmos utilizando contas individualizadas.}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                ybar,
                enlarge x limits={abs=2.5cm},
                bar width=0.65cm,
                width=\textwidth,
                height=.5\textwidth,
                legend style={at={(0.5,1)},
                    anchor=north,legend columns=-1},
                symbolic x coords={Donald J. Trump, Ellen DeGeneres, Alex Jones},
                xtick=data,
                %nodes near coords,
                %nodes near coords align={vertical},
                ymin=0.4,ymax=0.88,
                ylabel={sensibilidade},
                legend image code/.code={%
                   \draw[#1, draw=none] (0cm,-0.2cm) rectangle (0.44cm,0.2cm);
                },
            ]
            \addplot [fill=myblue!75,postaction={pattern=north east lines, pattern color=Blue}] table[x=account,y=NBT]{\mydata};
            
            \addplot [fill=myred!70,postaction={pattern=horizontal lines, pattern color=Mahogany}] table[x=account,y=NBA]{\mydata};
            
            \addplot [fill=YellowOrange,postaction={pattern=vertical lines, pattern color=Yellow}] table[x=account,y=J48]{\mydata};
            
            \addplot [fill=ForestGreen,postaction={pattern=north east lines, pattern color=SkyBlue}] table[x=account,y=LMT]{\mydata};
            
            \legend{NBayesTexto, NBayesAtributos, J48, LMT}
        \end{axis}
    \end{tikzpicture}
    \fonte{Produção do próprio autor.}
    \label{tik:sensibilidade-individual}
    \end{figure}
    
    \par Dentre as contas testadas, aquela que obteve resultados mais relevantes foi a de Alex Jones, sendo este, inclusive, o usuário detentor do maior número de tuítes presentes na base. Além da melhor acurácia dentre os demais casos, os valores obtidos com essa conta tornam-se interessantes pela consistência entre as métricas para os modelos aplicados sobre os atributos coletados. Isso pode ser observado comparando valores de sensibilidade.
    
    \par Ao comparar a sensibilidade entre as contas de Alex Jones e Donald Trump, nitidamente os resultados são melhores para esta segunda. Porém, ao analisar os valores de especificidade, os resultados para Donald Trump se comportam de maneira completamente inversa, sendo este o pior dos casos, enquanto que para Alex Jones os valores se mantém. Isso mostra, no caso da conta do atual presidente dos Estados Unidos, que aqueles modelos que obtêm as métricas de sensibilidade e especificidade de maneira completamente opostas, têm uma tendência maior em classificar os tuítes para uma determinada classe, o que não é o ideal.
    
    \par Assim como pôde ser visto no gráfico da Figura \ref{tik:engaj-balanc}, que relaciona engajamento e balanceamento, a conta de Ellen DeGeneres, dentre as três observadas nestes experimentos, obteve a menor taxa de engajamento que maximizasse a distribuição dos dados entre as classes. Curiosamente, esta também foi a conta com os piores resultados, tanto de acurácia quanto sensibilidade. Este fator leva a crer que ao considerar usuários com uma taxa de engajamento muito baixa, as análises gerais também podem ter seus resultados afetados negativamente. Para identificar o que pode levar a este cenário, seriam necessárias análises mais aprofundadas sobre a relação dos atributos com a popularidade dos tuítes desta conta.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % CONCLUSÕES % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\chapter{Conclusões}
\label{sec:conclusao}

    \par Medir a variação do índice de popularidade pode ser do interesse de administradores de grandes contas do Twitter, pois pode indicar o sucesso ou fracasso de uma determinada campanha realizada ou a dimensão de um escândalo, e tendo consciência disso, ações preventivas ou corretivas podem ser tomadas e sua repercussão pode ser monitorada. Tratando-se de personalidades públicas, é importante identificar quais assuntos e/ou abordagens agradam mais o público-alvo para que assim possam ser mantidas ou evitadas. Assim, pode ser relevante poder prever se uma mensagem tem maior probabilidade de se tornar popular antes mesmo de publicá-la.
    
    \par Os resultados alcançados neste trabalho, reforçados pelo que pôde ser observado em \cite{artigo:oliveira:18} no que se refere a influência dos atributos, mostram que modelos de aprendizagem de máquina podem sim realizar a classificação da popularidade de tuítes. Além disso, a partir dos experimentos realizados e apresentados no Capítulo \ref{sec:experimentos}, também pode-se concluir que:
    
    \begin{itemize}
        \item Análises utilizando todas as contas da base mostram melhores resultados de acurácia para o algoritmo Naive Bayes aplicado ao texto das mensagens;
        \item No caso de análises por contas individualizadas, diferentes algoritmos podem obter os melhores resultados, dependendo das especifidades de cada usuário;
        \item A utilização de contas que possuam um engajamento muito baixo por parte de seus seguidores pode dificultar a classificação da popularidade dos tuítes;
        \item A realização de análises individualizadas é realmente relevante, pois os melhores atributos de usuário não são necessariamente os mesmos para os demais.
    \end{itemize}

    \par Como trabalhos futuros, pretende-se realizar análises mais completas sobre as contas individualizadas, incluindo a obtenção de uma quantidade realmente significativa de tuítes para cada uma das contas acompanhadas. Juntamente a isso, pretende-se realizar análises sobre a diferença na influência que cada atributo exerce sobre os modelos quando aplicados a diferentes contas.
    
    \par Além disso, podem ser elencados como trabalhos futuros a realização de experimentos utilizando outros modelos de aprendizagem de máquina, considerando algoritmos genéticos, redes neurais e aprendizagem profunda. O uso de algoritmos deste tipo é cada vez mais difundido e, se aliado a outras técnicas como \textit{word embedding}, pode vir a trazer resultados muito interessantes. Destacam-se neste contexto as redes neurais convolucionais e as de Memória de Longo Prazo (LSTM, do inglês: \textit{Long Short-Term Memory}).

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % FIM DAS PAGINAS TEXTUAIS % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 	
% % % % % % % % % % % % % BIBLIOGRAFIA  % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 	

\bibliografia{referencias}  %%%%% BIBLIOGRAFIA -> NOME DO ARQUIVO *.BIB	
	
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 	
% % % % % % % % % % % % % APÊNDICES % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 	
\apendice %%%% TEXTOS A PARIR DESTE PONTO SERÃO CONSIDERADOS APÊNDICES

    %\chapter{Demonstração de algo}
    %\label{sec:apendice-demonst-algo}
            %\par Algo como apêndice.  
        
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 	
% % % % % % % % % % % % % % % ANEXOS  % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 	
\anexo    %%%% TEXTOS A PARIR DESTE PONTO SERÃO CONSIDERADOS ANEXOS

    \chapter{Tabela completa dos dados coletados por conta}
    \label{anexo-tebela-contas}
    
    \begin{table}[ht]
    \centering
    \caption{Dados coletados por conta}
    \label{tab:todas-contas-tweets}
    \begin{tabular}{|l|r|r|r|r|}
    \hline
    \textbf{Conta}  & \multicolumn{1}{l|}{\textbf{Tuítes}} & \multicolumn{1}{l|}{\textbf{Retuítes}} & \multicolumn{1}{l|}{\textbf{Curtidas}} & \multicolumn{1}{l|}{\textbf{Seguidores}} \\ \hline
    Alex Jones 			& 4672	& 1930401	& 620015	& 817779 	\\ \hline
    Ellen DeGeneres		& 822	& 2653308	& 7886125	& 77966272 	\\ \hline
    Donald J. Trump		& 701	& 15034127	& 62231949	& 51954765 	\\ \hline
    NASA				& 613	& 568676	& 1631924	& 29550297 	\\ \hline
    Jimmy Fallon		& 353	& 316448	& 1314721	& 51164006 	\\ \hline
    Katy Perry			& 227	& 939573	& 2203336	& 109563129 \\ \hline
    Google				& 162	& 34052		& 100543	& 20644472 	\\ \hline
    Pope Francis		& 115	& 1446489	& 5843421	& 17799966 	\\ \hline
    SpaceX				& 100	& 288816	& 779356	& 7001517 	\\ \hline
    Bill Gates			& 97	& 164657	& 848035	& 46101176 	\\ \hline
    Elon Musk			& 95	& 613369	& 3020961	& 21768873 	\\ \hline
    Neil deGrasse Tyson	& 82	& 1002532	& 3771544	& 12746436 	\\ \hline
    Lady Gaga			& 74	& 584597	& 2616566	& 78670710 	\\ \hline
    General Motors		& 60	& 1516		& 4666		& 653397 	\\ \hline
    Twitter				& 56	& 88568		& 121131	& 62888709 	\\ \hline
    Melinda Gates		& 53	& 10995		& 37325		& 2414678 	\\ \hline
    Anitta				& 48	& 18538		& 55008		& 7078705 	\\ \hline
    Amazon.com			& 45	& 1770		& 3769		& 2811240 	\\ \hline
    Rihanna				& 42	& 283679	& 1702401	& 88264703 	\\ \hline
    Cristiano Ronaldo	& 40	& 431103	& 3270122	& 72951646 	\\ \hline
    Sundar Pichai		& 28	& 21172		& 84020		& 1845772 	\\ \hline
    Neymar Jr			& 26	& 67060		& 641590	& 39610118 	\\ \hline
    Barack Obama		& 24	& 2875662	& 13890988	& 102464343 \\ \hline
    Oprah Winfrey		& 23	& 108606	& 622587	& 42536149 	\\ \hline
    Tim Cook			& 22	& 65558		& 291588	& 10927420 	\\ \hline
    Satya Nadella		& 22	& 9358		& 25546		& 1692335 	\\ \hline
    Tesla				& 18	& 38386		& 185163	& 2674338 	\\ \hline
    Taylor Swift		& 18	& 295405	& 787216	& 85826401 	\\ \hline
    Jeff Bezos			& 11	& 30171		& 131514	& 567875 	\\ \hline
    Netflix				& 6		& 19113		& 25522		& 3858644 	\\ \hline
    \end{tabular}
    \end{table}

\end{document}

